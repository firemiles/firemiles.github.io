[{"categories":["linux"],"content":"WSL2 是 Windows 提供的 Linux 虚拟环境，但是 Kernel 经过了修改，无法直接安装内核头文件，导致一些内核组件无法使用，包括bpftrace，本文主要简单记录内核头文件的安装，其他的内核组件也可以使用内核头文件从编译获取。","date":"2022-04-23","objectID":"/2022/wsl2%E5%AE%89%E8%A3%85%E5%86%85%E6%A0%B8%E5%A4%B4%E6%96%87%E4%BB%B6/","tags":["linux"],"title":"WSL2安装内核头文件","uri":"/2022/wsl2%E5%AE%89%E8%A3%85%E5%86%85%E6%A0%B8%E5%A4%B4%E6%96%87%E4%BB%B6/"},{"categories":["linux"],"content":"前言 一般 Linux 的发行版直接使用软件源就可以安装内核模块和内核头文件，但是WSL2作为一个特殊的版本， 大部分内核模块无法安装，也无法直接安装内核头文件，还有部分依赖内核头文件的工具也无法运行，本文主要介绍内核头文件的安装。 ","date":"2022-04-23","objectID":"/2022/wsl2%E5%AE%89%E8%A3%85%E5%86%85%E6%A0%B8%E5%A4%B4%E6%96%87%E4%BB%B6/:1:0","tags":["linux"],"title":"WSL2安装内核头文件","uri":"/2022/wsl2%E5%AE%89%E8%A3%85%E5%86%85%E6%A0%B8%E5%A4%B4%E6%96%87%E4%BB%B6/"},{"categories":["linux"],"content":"安装 第一步先去github上下载WSL2内核源码，仓库在 https://github.com/microsoft/WSL2-Linux-Kernel 。下载当前运行的内核版本。这里以4.19.121为例 开始安装依赖 apt install libelf-dev build-essential pkg-config apt install bison build-essential flex libssl-dev libelf-dev bc 编译 tar -zvxf 4.19.121-microsoft-standard.tar.gz cd WSL2-Linux-Kernel-4.19.121-microsoft-standard.tar.gz zcat /proc/config.gz \u003e .config make -j $(nproc) make -j $(nproc) modules_install 编译过程中可能会出现一些报错，一般是还缺少部分依赖，通过Google可以找到解决办法。 编译完成后，在 /lib/modules/ 会出现 4.19.121-microsoft-standard 目录，头文件就可以使用了，借助头文件，其他的内核模块也可以自行编译安装。 ","date":"2022-04-23","objectID":"/2022/wsl2%E5%AE%89%E8%A3%85%E5%86%85%E6%A0%B8%E5%A4%B4%E6%96%87%E4%BB%B6/:2:0","tags":["linux"],"title":"WSL2安装内核头文件","uri":"/2022/wsl2%E5%AE%89%E8%A3%85%E5%86%85%E6%A0%B8%E5%A4%B4%E6%96%87%E4%BB%B6/"},{"categories":["linux"],"content":"参考资料 WSL2 下的 kernel header 的安装 ","date":"2022-04-23","objectID":"/2022/wsl2%E5%AE%89%E8%A3%85%E5%86%85%E6%A0%B8%E5%A4%B4%E6%96%87%E4%BB%B6/:3:0","tags":["linux"],"title":"WSL2安装内核头文件","uri":"/2022/wsl2%E5%AE%89%E8%A3%85%E5%86%85%E6%A0%B8%E5%A4%B4%E6%96%87%E4%BB%B6/"},{"categories":["kubernetes","network"],"content":"转眼开发和维护Kubernetes容器网络快3年了，从一个懵懵懂懂的新手，到分析容器网络问题如数家珍，期间遇到了数不清的奇奇怪怪的案例，特此记录下给有需要的人","date":"2020-07-19","objectID":"/2020/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%AA%E9%97%AE%E9%A2%98/","tags":["kubernetes","network"],"title":"容器网络的怪问题","uri":"/2020/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%AA%E9%97%AE%E9%A2%98/"},{"categories":["kubernetes","network"],"content":"案例太多，一次写完有点太难为我，我就想到哪写到哪，保持更新。 ","date":"2020-07-19","objectID":"/2020/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%AA%E9%97%AE%E9%A2%98/:0:0","tags":["kubernetes","network"],"title":"容器网络的怪问题","uri":"/2020/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%AA%E9%97%AE%E9%A2%98/"},{"categories":["kubernetes","network"],"content":"长连接报文重传失败 有个客户来找，说他们的应用Server端日志里经常有长连接中断的消息，需要我们定位中断的原因。 接到这个问题时属实挠头，看了客户的错误日志，一般中断发生的频率极低，一天只出现个位数，我们尝试复现问题未果。但是客户就是上帝，接了问题单就要定位，我们的SRE比较有毅力，一连抓了3天的报文，根据报错日志，把有问题的报文挑了出来，我们进行分析。 通过wireshark工具分析TCP流，我们发现有问题的报文都是连接时间超过2小时没有报文，然后Server端突然发送了一个报文，但是客户端并没有收到这个报文，重发几次后连接就中断了。定位到这儿问题已经很明显了，客户没有使用TCP keepalive，导致连接长时间没报文，最后报文在发出去后在 VPC 中被丢了。 VPC 一般只会在安全组位置进行丢包，这很可能是安全组导致的丢包。查看了安全组规则，确实没有放通Server到Client端的规则，只放通了Client到Server的规则，也就是说只能由Client主动连接Server端，反之不行。 安全组的实现一般会使用连接跟踪表，当Client端发起连接，和Server端建立TCP连接时，连接跟踪表会记录这条连接，允许Client和Server在这条连接上传输数据。但是连接跟踪表是有超时时间的，一般就2小时，当两小时没有报文命中时，就老化掉该规则，这时Server端再发送报文时，就被安全组拒绝了。客户的问题应该就是这个原因。 这种情况一般建议客户开启TCP keepalive，这个问题并不是容器网络特有的问题，普通网络都会遇到。 ","date":"2020-07-19","objectID":"/2020/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%AA%E9%97%AE%E9%A2%98/:1:0","tags":["kubernetes","network"],"title":"容器网络的怪问题","uri":"/2020/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%AA%E9%97%AE%E9%A2%98/"},{"categories":["kubernetes","network"],"content":"长连接出现连接拒绝 容器网络还遇到一个客户来找我们，说他们POC测试的时候发现测试多轮大量长连接访问容器中的Server时会有一定几率出现Connect Refused错误。 接到问题后祭出tcpdump神器进行抓包，先简单描述下网络路径： 访问NodePort DNAT成Pod IP SNAT成GW IP Client --------------\u003e VM1 -----------\u003e DNAT ------------\u003e SNAT -------------\u003e Server Pod 我们抓两个位置的包 VM1 和 Server Pod，当出现Connect Refused时，Server Pod确实收到了报文，但是却回了一个RST报文。面对这种情况，头脑风暴分析了下可能的原因： nginx 有问题 连接数满了 连接被占用了 原因1不太可能 原因2我们查看了系统参数，连接数并没有达到上限，也排除 原因3我们在抓包的同时继续用netstat查看当前连接状态，发现当出现Connect Refusted报文时，果然连接仍然被占用着。 为什么会连接冲突呢，问题肯定出在SNAT的过程中，SNAT挑选的源端口有问题。通过分析报文，突然发现这些长连接也有一个特点，连接建立后并没有数据的传输，只是一直占用的通道，看到这里心中已经对问题的根因有了大致的猜想，肯定和连接跟踪超时有关。查看了主机和容器的 tcp_keepalive_time 的值，果然主机配置了1800，容器是7200，不同的timeout值，使得主机在1800后释放了tcp连接，重新分配的源端口给新的连接，而容器并未释放，最终导致访问Server返回Connect Refused错误。 这种情况我们自然建议可以将主机的 tcp_keepalive_time 改回成 7200，和容器保持一致，基本避免了该错误的发生。 ","date":"2020-07-19","objectID":"/2020/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%AA%E9%97%AE%E9%A2%98/:2:0","tags":["kubernetes","network"],"title":"容器网络的怪问题","uri":"/2020/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%AA%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"Firemiels 的个人博客。 ","date":"2020-05-31","objectID":"/about/:0:0","tags":null,"title":"关于该博客","uri":"/about/"},{"categories":["golang"],"content":"reflect 介绍 计算机科学中，反射(reflect) 指计算机程序在运行时（runtime）可以访问、检测和修改它本身状态或行为的一种能力。用比喻来说，反射就是程序在运行时能够“观察”并且修改自己的行为。 反射和内省（type introspection）不同，内省机制仅指程序在运行时对自身信息（称为元数据）的检测；反射机制不仅包括要能运行在对程序自身信息进行，还要能进一步根据这些信息改变程序状态或结构。 早期语言汇编包含反射能力，动态修改指令或对它们进行分析等等反射功能时很平常的。编程发展到如C语言等高抽象层次语言时，这种实践消失了，带有反射特性的高级编程语言要更晚出现。 golang 作为一个诞生较晚的现代语言，自然也支持反射能力。通过标准库 reflect 包我们可以使用 golang 提供的这个能力。 ","date":"2020-03-29","objectID":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/:1:0","tags":["golang","reflect"],"title":"golang的reflect使用","uri":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/"},{"categories":["golang"],"content":"Golang reflect 原则 ","date":"2020-03-29","objectID":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/:2:0","tags":["golang","reflect"],"title":"golang的reflect使用","uri":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/"},{"categories":["golang"],"content":"interface 类型 reflect 建立在类型系统上，我们先从 Go 的类型系统开始讲起。Go 是静态类型语言，所有的变量都有对应的静态类型，因此所有变量的类型在编译时就已经确定：int,float32,*MyType,[]byte等等。 如果我们定义 type MyInt int var i int var j MyInt 那么 i 是 int 类型，而 j 是 MyInt 类型。两个变量拥有不同的静态类型，尽管它们的底层类型是一样的，但是它们之间的赋值必须通过显式的类型转换完成。 interface type 是一类非常重要的类型，它代表一些方法的集合。interface 变量能够存储所有实现了 interface 中的方法的变量。一个广为人知的例子是 io.Reader 和 io.Writer。 // Reader is the interface that wraps the basic Read method. type Reader interface { Read(p []byte) (n int, err error) } // Writer is the interface that wraps the basic Write method. type Writer interface { Write(p []byte) (n int, err error) } 任何类型实现上述定义的 Read 或 Write 方法，我们认为该类型实现了 Reader 或 Writer 接口。 var r io.Reader r = os.Stdin r = bufio.NewReader(r) r = new(bytes.Buffer) // and so on 很重要的一点是，无论 r 的值是什么，r 的类型永远是 io.Reader，go 是静态类型，而 r 的静态类型是 io.Reader 。 空接口类型是一个十分重要的类型。 interface{} 它代表空方法的集合，它可以接收任意值，包括零值或有方法的值。 有些人可能认为Go的interface是动态类型，其实这是误解，它们是静态类型：interface 类型的变量永远是相同的静态类型，但是存储在interface中的值在运行时可以修改类型，该值要求实现interface定义的方法集合。 ","date":"2020-03-29","objectID":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/:2:1","tags":["golang","reflect"],"title":"golang的reflect使用","uri":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/"},{"categories":["golang"],"content":"interface 的细节 interface 类型的变量存储了一个对值：赋值给该interface的值；以及该值的类型。 var r io.Reader tty, err := os.OpenFile(\"/dev/tty\", os.O_RDWR, 0) if err != nil { return nil, err } r = tty r 存储了(value, type)对：(tty, *os.File)。需要注意 *os.File 实现了比 Read 更多的方法，但是使用 Read interface只能访问Read 中的方法。 var w io.Writer w = r.(io.Writer) 通过赋值给 Write 接口，我们可以访问 tty 中实现的 Write 中的方法。 我们还可以这样 var empty interface{} empty = w 空的interface仍然包含了相同的pair, (tty, *os.File)。它的用处是：空的interface可以接收任意值并保留该值的所有信息。 这里不需要进行类型断言，因为 Write 接口满足空interface类型要求，而 Read 接口和 Wirte 接口的方法集并不匹配，我们需要显式进行类型断言，告诉编译器我们知道它们存储的值是满足接口的。 还有很重要的一点要记住：interface中存储的pair是（value， concrete type），并不是 (value, interface type)。所以interface不能保存interface 值。 ","date":"2020-03-29","objectID":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/:2:2","tags":["golang","reflect"],"title":"golang的reflect使用","uri":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/"},{"categories":["golang"],"content":"第一个法则： 可以从 interface 值获取反射对象 先说基本功能，反射是测试interface中存储的值和类型的机制。我们需要了解 package reflect 中的 Type 和 Value。这两个类型可以访问interface中的内容。reflect.TypeOf 和 reflect.ValueOf 用来从interface中获取 reflect.Type 和 reflect.Value 。 package main import ( \"fmt\" \"reflect\" ) func main() { var x float64 = 3.4 fmt.Println(\"type:\", reflect.TypeOf(x)) } // type: flot64 反射对象的第二个属性是 Kind， 它是底层类型，非静态类型，例如反射对象包含用户自定义类型的值： type MyInt int var x MyInt = 7 v := reflect.ValueOf(x) // v.Kind() == reflect.Int v 的 Kind 是 reflect.Int，但是 x 的静态类型是 MyInt，不是int。 ","date":"2020-03-29","objectID":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/:2:3","tags":["golang","reflect"],"title":"golang的reflect使用","uri":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/"},{"categories":["golang"],"content":"第二个法则： 可以从反射对象获取 interface 值 获得一个reflect.Value 后，我们可以使用 Interface() 方法恢复 interface 值。该方法将type和value打包放入interface表达式中，并将它返回。 // Interface returns v's value as an interface{}. func (v Value) Interface() interface{} 之后你可以这么处理 y := v.Interface().(float64) // y will have type float64. fmt.Println(y) 我们还可以简化，fmt.Println 的参数是空 interface，他们在方法内部会做解包操作，因此我们只需要直接将interface传入。 fmt.Println(v.Interface()) ","date":"2020-03-29","objectID":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/:2:4","tags":["golang","reflect"],"title":"golang的reflect使用","uri":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/"},{"categories":["golang"],"content":"第三个法则：想要修改反射对象，对象的指必须是settable的 第三法则比较难懂，要结合法则一进行理解。 var x float64 = 3.4 v := reflect.ValueOf(x) v.SetFloat(7.1) // Error: will panic. 结果会 panic 并输出信息。 panic: reflect.Value.SetFloat using unaddressable value 错误的原因是 v 不是 addressable 的，Settable 是 reflect.Value 的一个属性，不是所有的 reflect.Value 都有该属性。 CanSet 方法输出 settable 属性 var x float64 = 3.4 v := reflect.ValueOf(x) fmt.Println(\"settability of v:\", v.CanSet()) // settability of v: false Settablity 是一个 bit 类似 addressability，但是更严格。这个属性表述反射对象可以修改创建该反射对象的原始变量的值。Settability 由反射对象是否持有原始对象决定。 当我们使用 var x float64 = 3.4 v := reflect.ValueOf(x) 反射对象只持有了 x 的 copy，并不是原始对象，因此 v.SetFloat(7.1) 如果允许运行成功，那么它修改的也不是x，而是反射对象内部的一个值，这会让开发者产生疑惑。所以这并不被允许，settability 属性就是用来避免该问题。 如果我们想要修改原始对象，那么我们可以使用指针： var x float64 = 3.4 p := reflect.ValueOf(\u0026x) // Note: take the address of x. fmt.Println(\"type of p:\", p.Type()) fmt.Println(\"settability of p:\", p.CanSet()) // type of p: *float64 // settability of p: false 这里 p 也是不可设置的，但是我们并不想修改 p，我们想要修改 p 指向的对象。我们可以使用 Elem 方法获取 p 指向的对象，该方法获取指针指向的元素，并保存成 reflect.Value 类型返回。 v := p.Elem() fmt.Println(\"settability of v:\", v.CanSet()) // settability of v: true 在这里我们可以修改 x 了。 v.SetFloat(7.1) fmt.Println(v.Interface()) fmt.Println(x) // 7.1 // 7.1 ","date":"2020-03-29","objectID":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/:2:5","tags":["golang","reflect"],"title":"golang的reflect使用","uri":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/"},{"categories":["golang"],"content":"结构体 在我们前面的例子中，v 并不是指针本身，而是它派生出来的对象。这种方法的一个使用场景是修改结构体的字段。只有我们拥有结构体的地址，我们才可以修改它的字段。 下面是一个分析结构体值的例子。我们使用结构体变量的地址构建一个反射对象，这样我们可以通过该对象对它进行修改。 type T struct { A int B string } t := T{23, \"skidoo\"} s := reflect.ValueOf(\u0026t).Elem() typeOfT := s.Type() for i := 0; i \u003c s.NumField(); i++ { f := s.Field(i) fmt.Printf(\"%d: %s %s = %v\\n\", i, typeOfT.Field(i).Name, f.Type(), f.Interface()) } // 0: A int = 23 // 1: B string = skidoo 因为 s 是 settable 的，所以我们可以用它修改结构体字段。 s.Field(0).SetInt(77) s.Field(1).SetString(\"Sunset Strip\") fmt.Println(\"t is now\", t) // t is now {77 Sunset Strip} ","date":"2020-03-29","objectID":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/:2:6","tags":["golang","reflect"],"title":"golang的reflect使用","uri":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/"},{"categories":["golang"],"content":"总结 再重复一遍三法则： 可以从interface值获取反射对象 可以从反射对象获取interface值 想要修改反射对象，对像必须是settable 一旦你理解这三个反射原则，那么Go就变得更容易使用了。反射是一个需要小心使用的强大工具，可以帮助你的代码减少不必要的重复。 下一次我将介绍 encoding/json 的实现，真正深入学习反射的使用。 ","date":"2020-03-29","objectID":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/:2:7","tags":["golang","reflect"],"title":"golang的reflect使用","uri":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/"},{"categories":["golang"],"content":"参考 https://www.wikiwand.com/zh-hans/%E5%8F%8D%E5%B0%84_(%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6) https://golang.org/pkg/reflect/ https://blog.golang.org/laws-of-reflection https://colobu.com/2018/02/27/go-addressable/ https://studygolang.com/articles/938 Go Data Structures: Interfaces https://draveness.me/golang/docs/part2-foundation/ch04-basic/golang-reflect/ ","date":"2020-03-29","objectID":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/:3:0","tags":["golang","reflect"],"title":"golang的reflect使用","uri":"/2020/golang%E7%9A%84reflect%E4%BD%BF%E7%94%A8/"},{"categories":["network"],"content":"协议说明 DHCP 协议（动态主机设定协定）是一个用于局域网的网络协议，位于TCP/IP的应用层，使用UDP协议工作，主要有两个用途： 用于内部网络和网络服务商自动分配IP给用户 用于内部网络管理员对所有电脑作中央管理 DHCP 用一台或一组DHCP服务器来管理网络参数的分配，这种分配方式具有容错性。即使在一个仅拥有少量机器的网络中，DHCP仍然是有用的，因为一台机器可以不造成任何影响的被加入到网路中。 甚至对于很少改变地址的服务器，DHCP仍然被建议用来设置它们的地址。如果服务器需要被重新分配地址，尽可能不改变之前的配置。对于一些设备，如路由器和防火墙，则不应该使用DHCP。 DHCP 于 1993 年10月成为标准协议，前身是 BOOTP （Bootstrap Protocol， 引导程序协议），DHCP 被设计成向前兼容 BOOTP 协议。当前的DHCP定义可以在RFC 2131 找到，而基于IPv6的建议标准(DHCPv6)可以在RFC3315 中找到。 ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:1:0","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"协议结构 Op：消息操作代码，既可以是引导请求（BOOTREQUEST 1）也可以是引导答复（BOOTREPLY 2） Htype：硬件地址类型 Hlen：硬件地址长度 Hops：客户端设置为0，relay agent使用 Xid：处理ID Secs：从获取到IP地址或者续约过程开始到现在所消耗的时间 Flags：标记 Ciaddr：客户机IP地址 Yiaddr：“你的”（客户机）IP地址 Siaddr：在bootstrap中使用的下一台服务器的IP地址 Giaddr：用于导入的接替代理IP地址 Chaddr：客户机硬件 Sname：任意服务器主机名称，空终止符 File：DHCP发现协议中的引导文件名、空终止符、属名或者空，DHCP供应协议中的受限目录路径名 Options：可选参数字段。参考定义选择列表中的选择文件 ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:2:0","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"协议时序 sequenceDiagram participant Server(not selected) participant Client participant Server(selected) Note over Client: Begins initialization Client -\u003e\u003e+ Server(selected): DHCPDISCOVER Client -\u003e\u003e+ Server(not selected): DHCPDISCOVER Note over Server(selected): Determines configuration Server(selected) -\u003e\u003e- Client: DHCPOFFER Note over Server(not selected): Determines configuration Server(not selected) -\u003e\u003e- Client: DHCPOFFER Note over Client: Collects replies, Selects configuration Client -\u003e\u003e+ Server(selected): DHCPREQUEST Client -\u003e\u003e Server(not selected): DHCPREQUEST Note over Server(selected): Commits configuration Server(selected) -\u003e\u003e- Client: DHCPACK Note over Client: Initialization complete Note over Client: Graceful shutdown Client -\u003e\u003e Server(selected): DHCPRELEASE Note over Server(selected): Discards lease DHCP 客户端发送 DHCPDISCOVER 广播报文请求 DHCP 网络配置； Server 端收到后应答 DHCPOFFER 配置客户端；客户端选择一个 Server 以及它提供的网络参数，填写 server identifier option 后广播 DHCPREQUEST 报文； Server 接收到 DHCPREQUEST 报文，没被选中的 Sever 通过该报文确认 client 没有使用自己提供的配置，被选中的 Server 持久化客户端binding配置，并应答 DHCPACK 报文，DHCPACK 中的配置不能和之前的 DHCPOFFER 冲突，并且 Server 在该阶段并不检查提供的网络地址； 客户端接收到 DHCPACK 后，应该对参数作最后的检查（例如ARP检查获得的网络地址），并记录lease时间。如果客户端发现网络地址已经被占用了，客户端需要发送 DHCPDECLINE 消息给 Server 并等待至少10s后重启配置流程。 ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:3:0","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"DHCP 协议状态转移图 ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:4:0","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"DHCP 常用 Option 字段 ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:5:0","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"Subnet Mask 客户端子网掩码，如果subnet mask option和router option同时指定，subnet mask必须第一个。 Code Len Subnet Mask +-----+-----+-----+-----+-----+-----+ | 1 | 4 | m1 | m2 | m3 | m4 | +-----+-----+-----+-----+-----+-----+ ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:5:1","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"Router Option 指定客户端子网中的路由器IP列表。 Code Len Address 1 Address 2 +-----+-----+-----+-----+-----+-----+-----+-----+-- | 3 | n | a1 | a2 | a3 | a4 | a1 | a2 | ... +-----+-----+-----+-----+-----+-----+-----+-----+-- ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:5:2","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"Domain Name Server Option 为客户端指定DNS列表。 Code Len Address 1 Address 2 +-----+-----+-----+-----+-----+-----+-----+-----+-- | 6 | n | a1 | a2 | a3 | a4 | a1 | a2 | ... +-----+-----+-----+-----+-----+-----+-----+-----+-- ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:5:3","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"Host Name Option 指定客户端名字。 Code Len Host Name +-----+-----+-----+-----+-----+-----+-----+-----+-- | 12 | n | h1 | h2 | h3 | h4 | h5 | h6 | ... +-----+-----+-----+-----+-----+-----+-----+-----+-- ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:5:4","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"Domain Name 指定客户端hostname的在DNS中记录的域名。 Code Len Domain Name +-----+-----+-----+-----+-----+-----+-- | 15 | n | d1 | d2 | d3 | d4 | ... +-----+-----+-----+-----+-----+-----+-- ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:5:5","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"Interface MTU Option 网卡MTU。 Code Len MTU +-----+-----+-----+-----+ | 26 | 2 | m1 | m2 | +-----+-----+-----+-----+ ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:5:6","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"Static Route Option 指定客户端需要添加的静态路由。default route(0.0.0.0) 在静态路由中使用是非法的。 Code Len Destination 1 Router 1 +-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | 33 | n | d1 | d2 | d3 | d4 | r1 | r2 | r3 | r4 | +-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ Destination 2 Router 2 +-----+-----+-----+-----+-----+-----+-----+-----+--- | d1 | d2 | d3 | d4 | r1 | r2 | r3 | r4 | ... +-----+-----+-----+-----+-----+-----+-----+-----+--- ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:5:7","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"Classless Route Option 支持CIDR目的路由，如果客户端不支持，忽略该配置；如果客户端支持，当static route 和 classless route 同时配置时，忽略static route option。如果Server同时返回 classless route和router option，忽略router option。 很多客户端可能不支持该选项，Server 最好同时发送 classless route和router option，在 classless route和router option中同时指定默认网关。 当客户端请求classless route，同时请求static routes或routers option时，Server只需要发送classless route，不要发送static routes和routers option。 Code Len Destination 1 Router 1 +-----+---+----+-----+----+----+----+----+----+ | 121 | n | d1 | ... | dN | r1 | r2 | r3 | r4 | +-----+---+----+-----+----+----+----+----+----+ Destination 2 Router 2 +----+-----+----+----+----+----+----+ | d1 | ... | dN | r1 | r2 | r3 | r4 | +----+-----+----+----+----+----+----+ ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:5:8","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"Server Identifier DHCPOFFER 和 DHCPREQUEST 中用于指定 DHCP Server。 Code Len Address +-----+-----+-----+-----+-----+-----+ | 54 | 4 | a1 | a2 | a3 | a4 | +-----+-----+-----+-----+-----+-----+ ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:5:9","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"Client-identifier 客户端默认用硬件地址来作为ID，但是也可以用这个值作为ID，Server 可以使用这个id来存取客户端的配置。服务器可以用域名，虚拟机用机器UUID来设置该值。 Code Len Type Client-Identifier +-----+-----+-----+-----+-----+--- | 61 | n | t1 | i1 | i2 | ... +-----+-----+-----+-----+-----+--- ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:5:10","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"参考资料 DHCP WIKI RFC2131 Dynamic Host Configuration Protocol RFC3315 Dynamic Host Configuration Protocol for IPv6 (DHCPv6) RFC951 BOOTSTRAP PROTOCOL (BOOTP) RFC1542 Clarifications and Extensions for the Bootstrap Protocol RFC1533 DHCP Options and BOOTP Vendor Extensions RFC3442 The Classless Static Route Option for Dynamic Host Configuration Protocol (DHCP) version 4 ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:6:0","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["network"],"content":"附录 状态图源码 stateDiagram [*] --\u003e INIT INIT --\u003e SELECTING: -/Send DHCPDISCOVER SELECTING --\u003e SELECTING: DHCPOFFER/Collect replies SELECTING --\u003e REQUESTING: Select offerk/send DHCPREQUEST REQUESTING --\u003e REQUESTING: DHCPOFFER/Discard REQUESTING --\u003e INIT: DHCPNAK/Discard offer, DHCPACK (not accept.)/Send DHCPDECLINE REQUESTING --\u003e BOUND: DHCPACK/Record lease, set timers T1, T2 BOUND --\u003e BOUND: DHCPOFFER, DHCPACK, DHCPNAK/Discard BOUND --\u003e RENEWING: T1 expires/Send DHCPREQUEST to leasing server RENEWING --\u003e BOUND: DHCPACK/Record lease, set timers T1, T2 RENEWING --\u003e REBINDING: T2 expires/Broadcast DHCPREQUEST RENEWING --\u003e INIT: DHCPNAK/Halt network REBINDING --\u003e BOUND: DHCPACK/Record lease, set timers T1,T2 REBINDING --\u003e INIT: DHCPNAK, Lease expired/Halt network INIT_REBOOT --\u003e REBOOTING: -/Send DHCPREQUEST REBOOTING --\u003e BOUND: DHCPACK/Record lease, set timers T1, T2 REBOOTING --\u003e INIT: DHCPNAK/Restart ","date":"2020-02-24","objectID":"/2020/dhcp%E5%8D%8F%E8%AE%AE/:7:0","tags":["network","DHCP"],"title":"DHCP协议","uri":"/2020/dhcp%E5%8D%8F%E8%AE%AE/"},{"categories":["algorithm"],"content":"引子 最近在读计算机经典教科书《具体数学》，作为一个非科班的计算机从业者，仿佛打开了新的天地，原来我刷题遇到的算法问题很多都可以用数学方法解决，原来数学不光是高数、线代和微积分三座大山，离散数学在计算机上是绝配。为记录学习过程中的心得并分享，故展开具体数学系列博客，望与有缘人分享这份知识的喜悦。 和《具体数学》的章节安排一样，本博客作为系列第一篇，主要讨论递归算法，从难易程度分成三个部分：河内塔、平面上的直线、约瑟夫问题。它们有两个共同的特征：一是都曾被数学家反复研究过；二是它们的解都用了 递归 的思想。 ","date":"2020-01-04","objectID":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/:1:0","tags":["math","algorithm","Josephus problem"],"title":"具体数学-约瑟夫问题","uri":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/"},{"categories":["algorithm"],"content":"河内塔 THE TOWER OF HANOI 学习过递归算法的同学应该都知道知道河内塔，我当时就是通过河内塔入门了递归算法的。河内塔是由法国数学家爱德华·卢卡斯于1883 年发明的。给定一个由8个圆盘组成的塔，这些圆盘按照大小递减的的方式套在三根桩柱中的一根上。 我们的目的是要将整个塔移动到另一根桩柱上，每次只能移动一个圆盘，且较大的圆盘在移动过程中不能放置在较小的的圆盘上面。 现在问题来了：我们能做到的最好的解法是什么？也就是说，要完成这项任务移动多少次才是必须且足够的？ 研究这样的问题的最好的方法是对它稍加推广，如果有n个圆盘将会怎么样？ 事实上，研究递归问题，我们将会看到先研究小的情形是有益的。通过少量尝试就能看出如何移动3个圆盘的塔。 要用数学语言解决这个问题，我们自然需要引入适当的记号：命令并求解。我们称 $T_n$ 是根据卢卡斯的规则将圆盘从一根柱移动到另一根柱所需要的最少移动次数。那么，$T_1$ 显然是1，$T_2=3$ ，另外定义 $T_0=0$。 我们从宏观的角度来分析这个问题，如何将n个圆盘移动到柱子B。首先移动上面n-1个圆盘到柱子C，然后移动最大的圆盘到柱子B，最后将n-1个圆盘移动到柱子B。就像如何将大象放入冰箱一样，只要分三步。我们将这三步用数学语言进行表示： $$ T_n \\leq 2T_{n-1}+1 $$ 之所以用了 $\\leq$ ，没用 = ，是因为我们的构造仅证明了 $2T_{n-1}+1$ 次移动足够完成任务，但是没有证明必须要这么多次才能完成任务。 这里我没法用公式说明为什么，只能做一个思想游戏：假如我要把所有圆盘从A移动到B，必须把最大的圆盘先放到B，这个时候上面的n-1个圆盘必然在另一个柱子上，也就是说完成这一步必须要 $T_{n-1}+1$ 步，大圆盘放到B后，必须把n-1个圆盘也移动到B上，最少需要 $T_{n-1}$ 步，也就是说： $$ T_n \\geq 2T_{n-1}+1 $$ 综合两个不等式，我们可以得出当我们以完全正确的步骤移动河内塔时需要的移动次数： $$ \\begin{aligned} \u0026 T_0 = 0; \\\\ \u0026 T_n = 2T_{n-1}+1. \\end{aligned} \\tag{1.1} $$ 像（1.1）这样的一组等式我们称为递归式（recurrence），它给出一个边界值，以及一个递推关系的方程。有时我们也把单独的一般性方程称为递归式，尽管技术上还需要一个边界值来补足。 假如用代码实现，上述的递推关系已经可以完成变成了，我们可以使用递归调用简洁的实现河内塔计算。但是当n很大时，计算太耗时了。 递归的解 很美妙，也很容易理解，但是并不容易直接计算，在实际使用中，我们希望简化获得一个即漂亮又简洁的“封闭形式”。也就是 $T_n$ 的计算应该与上一个值 $T_{n-1}$ 无关, 只和n相关。 我们通过观察，很容易想到 $T_n$ 和 2 的幂相关，在通过初始几个数字的尝试，我们可以确定： $$ T_n = 2^n - 1, n \\geq 0 \\tag {1.2} $$ 至少在我们尝试 $n \\leq 6$ 时是成立的。再通过数学归纳法，很容易证明该公式对于 $n \\geq 0$ 都成立。 《具体数学》将解决这类问题分为了三个步骤： 研究小的情形。这有助于我们洞察该问题 对有意义的量求出数学表达式并给出证明。对于河内塔，就是递归式（1.1）。 对数学表达式求出封闭形式并证明，对于河内塔，就是递归解（1.2） ","date":"2020-01-04","objectID":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/:2:0","tags":["math","algorithm","Josephus problem"],"title":"具体数学-约瑟夫问题","uri":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/"},{"categories":["algorithm"],"content":"平面上的直线 LINES IN THE PLANE 第二个问题平面上的直线相信大家也都遇到过：一个蛋糕，切4到最多能分成几块（这里限定是一个平面上切）。我们把问题用数学语言重新翻译下并进行宽展：平面上n条直线所界定的的区域的最大个数 $L_n$ 是多少？这个问题于1826年被以为瑞士数学家坦纳首先解决。 我们再从最小情形开始研究。 $L_0 = 1$, $L_1 = 2$, $L_2 = 4$, $L_3 = 7$ 。 思考后，我们可以得出递推关系： 第n（n\u003e0）条直线使得区域增加k个，当且仅当它对k个已有区域进行了分裂； 而它对k个已有区域进行分裂，当且仅当它在k-1个不同的地方与之前的直线相交； 两条直线至多相交与一点，之前已有n-1条直线，因而这条新的直线与n-1条直线至多相交于n-1个不同的点，故必定有 $k \\leq n-1$，我们证明了上界 $$ L_n \\leq L_{n-1} + n, \\quad n \\gt 0. $$ 已知当 $n \\lt 4$ 时可以取到 =，我们采用数学归纳法来证明对于所有n都可以取到上界。 证明：已知 $n \\lt 4$ 时公式成立；假设当 n=k 时满足 $L_n = L_{n-1} + n$ 。需要证明当 n = k + 1 时公式仍然成立。 我们径直来放第k+1条直线，该直线不与之前任何一条直线平行，因此它与之前的k条直线相交，分隔出k+1个空间，即$L_{k+1} = L_k + k+1$，所以递归式为： $$ \\begin{aligned} \u0026 L_0 = 1; \\\\ \u0026 L_n = L_{n-1} + n, \\quad n \\gt 0. \\end{aligned} \\tag {2.1} $$ 证明结束。 现在我们需要一个封闭形式的解，我们先观察 $L_n$ 的形式，发现递归形式很像是在求 $\\sum_{i=1}^ni$，高斯告诉我们，这个求和公式的值是 $$ S_n = \\frac {(n+1)n}{2}, \\quad n \\geq 0 $$ 对比 $L_n$ 的值，我们调整下式子。 $$ L_n = \\frac {(n+1)n}{2} + 1, \\quad n \\geq 0 $$ 再使用数学归纳法，可以证明这就是正确的解。 我们多次提到封闭形式，《具体数学》中有粗略定义：如果可以利用至多固定次数（其次数与n无关）的标准运算来计算量的 $f(n)$ 表达式，那么这个表达式是封闭的。当然有一些例外情况，例如，$n!$ 被证明是如此重要，故而我们都把它视为是一种基本运算，于是公式 $n!$ 就是封闭形式。 ","date":"2020-01-04","objectID":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/:3:0","tags":["math","algorithm","Josephus problem"],"title":"具体数学-约瑟夫问题","uri":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/"},{"categories":["algorithm"],"content":"平面上的折线 现在我们把问题做一个变形：假设我们用折线代替直线，每一条折线包含一个“锯齿”。平面上由n条这样的折线所界定的区域的最大个数 $Z_n$ 是多少？ 或许我们期待 $Z_n$ 是 $L_n$ 的两倍或者三倍。通过几个简单情况的观察。 我们发现折线的情况和直线类似，只是折线在“锯齿”处缺少了一处切割，少了两个区域。 也就是说放一条折线相当与放两条直线，但是需要减去两个区域。 $$ \\begin{aligned} Z_0 \u0026= 1 \\newline Z_n \u0026= Z_{n-1} + (2n - 1 + 2n) - 2 \\newline \u0026= Z_{n-1} + 4n - 3, \\quad n \\gt 0 \\end{aligned} $$ 我们将公式进行变形。 $$ Z_n - Z_{n-1} = 4n - 3 $$ 如果学习过微积分就能发现，这个形式很像微分的定义，在离散数学中，这种形式称为差分，这里不直接使用差分的性质，而是先自行推导 $Z_n$ 的计算。 $$ \\begin{aligned} Z_n \u0026= Z_0 + \\sum_{k=1}^{n}4n-3 \\\\ \u0026= 2n^2 - n + 1 \\\\ \\end{aligned} \\tag{2.2} $$ 方程（2.2）使用了求和累加，从 $Z_0$ 累加前后项差分值计算出 $Z_n$。《具体数学》中使用了 $L_n$ 来对 $Z_n$ 求值。 $$ Z_n = L_{2n} - 2n = 2n^2 - n + 1, n \\geq 0 $$ 比较 $L_n$ 和 $Z_n$， 我们发现对于大的n有 $$ \\begin{aligned} L_n \u0026\\sim \\frac {1}{2}n^2, \\\\ Z_n \u0026\\sim 2n^2; \\end{aligned} $$ 所以用折线所能得到的区域是用直线所能得到区域的大约4倍，也符合我们开始的直觉。 ","date":"2020-01-04","objectID":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/:3:1","tags":["math","algorithm","Josephus problem"],"title":"具体数学-约瑟夫问题","uri":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/"},{"categories":["algorithm"],"content":"约瑟夫问题 THE JOSEPHUS PROBLEM 终于到了本文的核心问题，也是《具体数学》中第一章的点睛之笔——约瑟夫问题。在这里我们将学习到如何一般化处理这类递归问题，不再依靠解体时的灵光乍现。 传说在犹太罗马战争期间，约瑟夫与其他他40名犹太反抗者困在了罗马人包围的洞穴中，这些反抗者宁愿自杀也不愿被活捉，于是决定围成一个圆圈，并沿着圆圈每个两个人杀死一个人，直到剩下两个人为止。但是约瑟夫和一个未被告发的同谋者不希望无谓的自杀，于是他迅速计算出他和朋友在这险恶的圆圈中应该站的位置。 我们对问题进行一些改动和简化：从围成标有记号1到n的圆圈的n个人开始，每隔一个人删去一个人，直到有一个人幸存下来，例如 $n=10$ 的起始图形： 消去的顺序是2，4，6，8，10，3，7，1，9，于是5幸存下来。问题：确定幸存者的号码，我们表示为 $J(n)$. 第一步，观察基本情形。 $n$ 1 2 3 4 5 6 $J(n)$ 1 1 3 1 3 5 似乎幸存者都是奇数，事实上，第一轮结束后，所有偶数都被消灭了，第二轮开始剩下的都是偶数。等等，我们似乎发现了一个递推关系：第一轮，第二轮，第三轮，···。直到某一轮只有一个人 $J(1)$， 那个人就是最终的幸存者。但是这个递推关系中还有一个问题，就是每一轮我们需要将幸存者重新编号，找到幸存者后，我们需要恢复幸存者的真实编号。这难不倒我们，我们可以将编号的关系带入到递归公式中。 当第一轮是偶数是： 第一轮 1 2 3 4 5 6 第二轮 1 x 2 x 3 x 当第一轮是奇数时： 第一轮 1 2 3 4 5 6 7 第二轮 x x 1 x 2 x 3 当第一轮是奇数时，需要把1号删除才能结束该轮，否则第二轮开始1号会存活，违反了游戏规则。 $$ \\begin{aligned} J(1) \u0026= 1; \\\\ J(2n) \u0026= 2J(n) - 1, \\quad n \\geq 1; \\\\ J(2n+1) \u0026= 2J(n) + 1, \\quad n \\geq 1. \\end{aligned} $$ 注意到我们用了 $2n$, $2n+1$ 的形式来书写公式，没有选择 $n/2$ 的形式，避免了增加n是偶数还是奇数的条件。 《具体数学》中对 $J(n)$ 的前几项展开进行了观察，发现结果和 n 与 2 的幂次相关，并使用数学归纳法获得封闭形式。 $$ J(2^m+l) = 2l + 1, \\quad m \\geq 0, \\quad 0 \\leq l \\lt 2 ^m \\tag{3.1} $$ 书中详细介绍了求解过程，这里我们不再是赘述。 到了这里，我们已经解决最后幸存的问题，但是相对于约瑟夫问题，我们还没完全解决，因为问题中要求计算最后两个幸存者。那么倒数第二的幸存者是谁呢。 我们使用类似的方法，定义倒数第二幸存者为 $I(n)$，可以得到一个递归公式。 $$ \\begin{aligned} I(2) \u0026= 2; \\\\ I(3) \u0026= 1; \\\\ I(2n) \u0026= 2I(n) - 1, \\quad n \\geq 2; \\\\ I(2n+1) \u0026= 2I(n) + 1, \\quad n \\geq 2; \\end{aligned} $$ 看起来这个递归式不好简化，这里先放一边，我在文章末尾进行解答。 ","date":"2020-01-04","objectID":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/:4:0","tags":["math","algorithm","Josephus problem"],"title":"具体数学-约瑟夫问题","uri":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/"},{"categories":["algorithm"],"content":"问题推广 这一节是递归问题求解的精华部分，如果你没有仔细阅读前面的部分，这一部分可不能再错过。 我们对 (3.1) 的公式进行变形，将n进行二进制展开。 $$ \\begin{aligned} n \u0026= (b_{m} b_{m-1} \\ldots b_1 b_0)2 \\\\ n \u0026= b{m}2^m + b_{m-1}2^{m-1} + \\cdots + b_{1}2^1 + b_{0}2^0 \\end{aligned} $$ 其中 $b_i$ 为0或1，而首位数字 $b_m$ 必定为 1。同时有 $n=2^m+l$ ，所以我们依次次有 $$ \\begin{aligned} n \u0026= (1b_{m-1}b_{m-2} \\cdots b_{1} b_{0})2, \\\\ l \u0026= (0b{m-1}b_{m-2} \\cdots b_{1} b_{0})2, \\\\ 2l \u0026= (b{m-1}b_{m-2} \\cdots b_{1} b_{0} 0)2, \\\\ 2l + 1 \u0026= (b{m-1}b_{m-2} \\cdots b_{1} b_{0} 1)2, \\\\ J(n) \u0026= (b{m-1}b_{m-2} \\cdots b_{1} b_{0} b_{m})_2. \\end{aligned} $$ 所以我们就证明了 $$ J((b_{m}b_{m-1}b_{m-2} \\cdots b_{1} b_{0})2) = (b{m-1}b_{m-2} \\cdots b_{1} b_{0} b_{m})_2 $$ 在计算机代码中，这个操作就是 $n$ 向左循环移动一位，我们就可以计算出 $J(n)$ ! 让我更加一般化这个结果，引入常数 $\\alpha$ 、$\\beta$ 、 $\\gamma$ ，力图对更加一般的递归式 (3.2) 求出一个封闭形式，以此来研究这个问题。 $$ \\begin{aligned} f(1) \u0026= \\alpha ; \\\\ f(2n) \u0026= 2f(n) + \\beta, \\quad n \\geq 1; \\\\ f(2n+1) \u0026= 2f(n) + \\gamma, \\quad n \\geq 1. \\end{aligned} \\tag{3.2} $$ 这里我们先尝试几个数字判断 $f(n)$ 和常数之间的关系，然后可以合理猜测，$f(n)$ 与 $\\alpha$ 、$\\beta$ 、$\\gamma$ 的一次项存在某个依存关系，我们将它表示成形式 $$ f(n) = A(n)\\alpha + B(n)\\beta + C(n)\\gamma \\tag{3.3} $$ 我们要求形式中的$A(n),B(n),C(n)$对于任意常数成立,也就是与常数不相关。我们可以使用取特殊值的方式求解该方程 $取 \\alpha = 1, \\beta = \\gamma = 0$ $$ \\begin{aligned} f(1) \u0026= A(1) = 1; \\\\ f(2n) \u0026= A(2n) = 2f(n) = 2A(n), \\quad n \\geq 1; \\\\ f(2n+1) \u0026= A(2n+1) = 2f(n) = 2A(n), \\quad n \\geq 1. \\end{aligned} $$ 看起来有 $A(n)=2^m$。 我们再取特殊值，但是我们不再直接取值并使用递归式，因为解递归式比较麻烦，我们发现除了递归式，我们还有一个已知等式 $f(n) = A(n)\\alpha + B(n)\\beta + C(n)\\gamma$，使用这个等式可以比较容易计算 $B(n)$ 和 $C(n)$ 的值。 我们取常数函数 $f(n)=1$，研究是否有任何常数 $(\\alpha, \\beta, \\gamma)$ 能定义它。将它带入递归式(3.2)，可以求得 $(\\alpha, \\beta, \\gamma) = (1,-1,-1)$, 带入式子 (3.3) 可以获得 $A(n)-B(n)-C(n)=f(n)=1$，同样的方式，带入 $f(n)=n$，我们可以获得 $(\\alpha,\\beta,\\gamma)=(1,0,1)$ ， $A(n)+C(n)=f(n)=n$。联立方程： $$ \\begin{aligned} A(n) \u0026= 2^m, \\quad 其中 n = 2^m + 1 且 0 \\leq l \\lt 2^m; \\\\ A(n) - B(n) - C(n) \u0026=1; \\\\ A(n) + C(n) \u0026= n. \\end{aligned} $$ 得到解： $$ \\begin{aligned} A(n) \u0026= 2^m \\\\ C(n) \u0026= n - A(n) = l \\\\ B(n) \u0026= A(n) - C(n) - 1 = 2^m - 1 - l \\end{aligned} $$ 上述求解过程描述了一套求解递归式的成套方法(repertoire method)。首先我们来寻求一组已知解的通用参数，这会给我们一整套可以求解的特殊情形。然后将特殊情形组合起来得到一般的情况。 这一方法运用于“线性的”递归式时最为成功，这里线性的含义就是它的解可以表示成任意参数与n的函数的乘积之和，比如式子（3.3） 我们再对约瑟夫递归式进行推广，令 $\\beta_0=\\beta, \\beta_1=\\gamma$，那么我们可以把递归式(3.2)改写成 $$ \\begin{aligned} f(1) \u0026= \\alpha; \\\\ f(2n+j) \u0026= 2f(n) + \\beta_j, \\quad j=0,1, \\quad n \\geq 1. \\end{aligned} \\tag{3.4} $$ 将递归式按照二进制展开，$b_m=1$ $$ \\begin{aligned} f((b_{m}b_{m-1} \\cdots b_1 b_0)2) \u0026= 2f((b{m}b_{m-1} \\cdots b_1)2) + \\beta{b_0} \\\\ \u0026= 4f((b_{m}b{m-1} \\cdots b_2)2) + 2\\beta{b_1} + \\beta_{b_0)} \\\\ \u0026= 2^mf((b_m)2) + 2^{m-1}\\beta{b_{m-1}} + \\cdots + 2\\beta_{b_{1}} + \\beta_{b_0} \\\\ \u0026= 2^m\\alpha + 2^{m-1}\\beta_{b_{m-1}} + \\cdots + 2\\beta_{b_{1}} + \\beta_{b_0} \\\\ \u0026= (\\alpha \\beta_{b_{m-1}} \\beta_{b_{m-2}} \\cdots \\beta_1 \\beta_0)_2 \\end{aligned} \\tag{3.5} $$ 利用这个公式，我们再来计算约瑟夫问题，其中 $\\alpha=1,\\beta_0=-1,\\beta_1=1$ 当 $n = 100 = (1100100)_2$时 改变表示法使我们对于一般的递归式(3.4)给出了紧凑解(3.5)，我们还可以更加一般化(3.4) $$ \\begin{aligned} f(j) \u0026= \\alpha_j, \\quad 1 \\leq j \\lt d; \\\\ f(dn+j) \u0026= cf(n) + \\beta_j, \\quad 0 \\leq j \\lt d, n \\geq 1. \\end{aligned} \\tag{3.6} $$ 与上一个递归式是相同的，除了这里是从基数为d的数着手，而产生的值是用基数c表示之外，这就是说，它有变动基数的解 $$ f((b_{m}b_{m-1} \\cdots b_1 b_0)d) = (\\alpha{b_m} \\beta_{b_{m-1}} \\beta_{b_{m-2}} \\cdots \\beta_{b_1} \\beta_{b_0})_c \\tag{3.7} $$ 这个公式十分便利，如果你没有看完前面的证明，那这个公式一定要学会使用。我们用它来解决一个递归式。 $$ \\begin{aligned} f(1) \u0026= 34; \\\\ f(2) \u0026= 5; \\\\ f(3n) \u0026= 10f(n) + 76, \\quad n \\geq 1; \\\\ f(3n+1) \u0026= 10f(n) - 2, \\quad n \\geq 1; \\\\ f(3n+2) \u0026= 10f(n) + 8, \\quad n\\geq 1; \\end{aligned} $$ 假设我们计算 $f(19)$，现在有 $19=(201)_3$ $$ f(19) = f((201)3) = (5 \\quad 76 \\quad -2){10} = 1258 $$ ","date":"2020-01-04","objectID":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/:4:1","tags":["math","algorithm","Josephus problem"],"title":"具体数学-约瑟夫问题","uri":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/"},{"categories":["algorithm"],"content":"最后的问题 现在我们可以讨论上面那个倒数第二幸存者的问题了，先把前文求得的递归公式再写一遍： $$ \\begin{aligned} I(2) \u0026= 2; \\\\ I(3) \u0026= 1; \\\\ I(2n) \u0026= 2I(n) - 1, \\quad n \\geq 2; \\\\ I(2n+1) \u0026= 2I(n) + 1, \\quad n \\geq 2; \\end{aligned} $$ 我们想要使用最终获得的通用公式(3.7)来求解，但是有一个问题：我们没有 $\\alpha_1$ 的定义，而且 $n=1$ 时没有定义。但是这难不到我们，回想下通用公式的推导过程 $$ \\begin{aligned} f((b_{m}b_{m-1} \\cdots b_1 b_0)d) \u0026= df(b{m}b_{m-1} \\cdots b_1) + \\beta_{b_0} \\\\ \u0026= c^{m-1}f((b_{m}b_{m-1})) + c^{m-1}\\beta_{b_{m-2}} + \\cdots + c\\beta_{b_1} + \\beta_{b_0} \\end{aligned} $$ 由于 n 在 1 时没有意义，所以我们最后不再展开 $b_{b}b_{m-1}$，而是整体进行处理，所以有 $$ f((b_{m}b_{m-1} \\cdots b_1 b_0)d) = (\\alpha{b_{m}b_{m-1}} \\beta_{b_{m-2} \\beta_{b_{m-2}}} \\cdots \\beta_{b_1} \\beta_{b_0})_c $$ 这个变形后的公式正好满足我们要求，我们现在用它来计算 $I(5)$, $I(41)$ $$ \\begin{aligned} I(5) \u0026= I((101)_2) = (2 \\quad 1)_2 = 5 \\\\ I(41) \u0026= I((101001)_2) = (2 \\quad 1 \\quad -1 \\quad -1 \\quad 1)_2 \\\\ \u0026= 2 * 16 + 8 - 4 - 2 + 1 = 35 \\end{aligned} $$ 所以约瑟夫的朋友应该在 35 号位。 再进一步推广，倒数第 k 个幸存者是几号？从上面的结论不难发现，不论是倒是第几个幸存者，递推公式是不变的，变化的只是初始值以及取值范围，所以倒数第 k 个幸存者可以表示成 $J_k(n)$： $$ \\begin{aligned} J_k(n) \u0026= J_k((b_{m}b_{m-1} \\cdots b_1 b_0)2) \\\\ \u0026= (\\alpha{b_{m}b_{m-1} \\cdots b_{m - \\log_2 k}} \\beta_{b_{m - \\log_2 k - 1}} \\cdots \\beta_{b_1} \\beta_{b_0})_2 \\end{aligned} \\tag{3.8} $$ 写到这里，约瑟夫类似的递归问题应该已经难不倒大家了，只要能写出递归式，就能转换成封闭形式，直接求解，这就是数学神奇的地方。 ","date":"2020-01-04","objectID":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/:5:0","tags":["math","algorithm","Josephus problem"],"title":"具体数学-约瑟夫问题","uri":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/"},{"categories":["algorithm"],"content":"参考资料 Ronald L.Graham,Donald E.Knuth,Oren Patashnik ．具体数学计算机基础（第2版） ：人民邮电出版社，2013：7 ","date":"2020-01-04","objectID":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/:6:0","tags":["math","algorithm","Josephus problem"],"title":"具体数学-约瑟夫问题","uri":"/2020/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98/"},{"categories":["openvswitch"],"content":"openvswitch 已经成为 SDN 网络的一块基石，是网络开发者无法绕过的一道关口。本文总结 openvswitch 的模块结构以及命令行工具，方便日常开发查询。2020年的第一篇博客，我们就来谈谈openvswitch。","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"OVS 架构 本文主要针对内核态 openvsiwth，用户态 openvswitch 的使用和调试不在本文的讨论范围内。 ovs 架构如上图所示，主要由内核 datapath 和用户空间的 vswitchd、 ovsdb 组成。 ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:1:0","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"主要模块 datapath 是负责数据交换的内核模块，从网口读取数据，并快速匹配Flowtable中的流表项，成功的直接转发，失败的 upcall 到 vswitchd 处理。它在初始化port binding 的时候注册钩子函数，把端口的报文处理接收到 ovs 内核模块。 vswitchd 是一个守护进程，是ovs的管理和控制服务，通过unix socket将配置信息保存到 ovsdb ，并通过 netlink 和内核模块交互。 ovsdb 则是 ovs 的数据库，保存 ovs 的配置信息。 ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:1:1","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"client与组件对应关系 组件 功能 ovs-dpctl datapath控制器,可以创建删除DP,控制DP中的FlowTables,最常使用show命令，其他很少手动操作 ovs-ofctl 流表控制器，控制bridge上的流表，查看端口统计信息等 ovsdb-tool 专门管理ovsdb的client ovs-vsctl 最常用的命令,通过操作ovsdb去管理相关的bridge,ports什么的 ovs-appctl 这个可以直接与openvswitch daemon进行交互 ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:1:2","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"常用子命令说明 ovs-dpctl show -s ovs-ofctl show, dump-ports, dump-flows, add-flow, mod-flows, del-flows ovsdb-tools show-log -m ovs-vsctl show 显示数据库内容 关于桥的操作 add-br, list-br, del-br, br-exits 关于port的操作 list-ports, add-port, del-port, add-bond, port-to-br 关于interface 的操作 list-ifaces, iface-to-br ovs-vsctl list/set/get/add/remove/clear/destroy table record column [value] 常见的表有bridge,controller,interface,mirror,netflow,open_vswitch,port,qos,queue,ssl,sflow. ovs-appctl list-commands, fdb/show, qos/show ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:1:3","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"日常操作 ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:2:0","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"查看有哪些桥，桥中有哪些ports，哪些interfaces root@l-network-1:~# ovs-vsctl list-br br-ex br-int br-tun root@l-network-1:~# ovs-vsctl list-ports br-tun patch-int vxlan-ac1c0509 vxlan-ac1c050d vxlan-ac1c051c vxlan-ac1c053f root@l-network-1:~# ovs-vsctl list-ifaces br-tun patch-int vxlan-ac1c0509 vxlan-ac1c050d vxlan-ac1c051c vxlan-ac1c053f # iface与ports同名. ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:2:1","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"查看 port，interface属于那个bridge， xxx-to-br root@l-network-1:~# ovs-vsctl port-to-br vxlan-ac1c0509 br-tun root@l-network-1:~# ovs-vsctl iface-to-br vxlan-ac1c0509 br-tun ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:2:2","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"查看隐藏的流表规则，很少使用 root@l-network-1:# ovs-appctl bridge/dump-flows br-ex duration=6067771s, n_packets=1313936898, n_bytes=881574100116, priority=0,actions=NORMAL table_id=254, duration=6067771s, n_packets=0, n_bytes=0, priority=2,recirc_id=0,actions=drop table_id=254, duration=6067771s, n_packets=0, n_bytes=0, priority=0,reg0=0x1,actions=controller(reason=no_match) table_id=254, duration=6067771s, n_packets=0, n_bytes=0, priority=0,reg0=0x2,actions=drop table_id=254, duration=6067771s, n_packets=0, n_bytes=0, priority=0,reg0=0x3,actions=drop ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:2:3","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"查看一些有用的统计信息 查看datapath统计信息.主要关注lost数值.hit表示datapath命中数,missed未命中，lost表示没有传递到用户空间就丢弃了. 主要关注lost值是否上升，如果上升说明存在问题了.该命令可以使用-s选项，会将每个port的统计信息也显示出来。 root@l-network-1:# ovs-dpctl show system@ovs-system: lookups: hit:2596765540 missed:6438005 lost:0 flows: 39 masks: hit:19416324706 total:10 hit/pkt:7.46 port 0: ovs-system (internal) port 1: tapd9a71635-53 (internal) port 2: tap82059645-8e (internal) port 3: tap3f0507b3-70 (internal) root@l-network-1:# ovs-dpctl show -s system@ovs-system: lookups: hit:2596836956 missed:6438236 lost:0 flows: 42 masks: hit:19416902233 total:10 hit/pkt:7.46 port 0: ovs-system (internal) RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 aborted:0 carrier:0 collisions:0 RX bytes:0 TX bytes:0 port 1: tapd9a71635-53 (internal) RX packets:4170 errors:0 dropped:0 overruns:0 frame:0 TX packets:1091973 errors:0 dropped:0 aborted:0 carrier:0 collisions:0 RX bytes:906944 (885.7 KiB) TX bytes:48392325 (46.2 MiB) port 2: tap82059645-8e (internal) RX packets:7130 errors:0 dropped:0 overruns:0 frame:0 TX packets:7379 errors:0 dropped:0 aborted:0 carrier:0 collisions:0 RX bytes:641578 (626.5 KiB) TX bytes:650492 (635.2 KiB) port 3: tap3f0507b3-70 (internal) RX packets:5505 errors:0 dropped:0 overruns:0 frame:0 TX packets:7549 errors:0 dropped:0 aborted:0 carrier:0 ovs-ofctl dump-ports br [port]也可以查看port的统计信息.这个命令优势是可以指定port. root@l-network-1:# ovs-ofctl dump-ports br-ex OFPST_PORT reply (xid=0x2): 19 ports port LOCAL: rx pkts=78668524, bytes=34522064349, drop=0, errs=0, frame=0, over=0, crc=0 tx pkts=78827893, bytes=5746347600, drop=0, errs=0, coll=0 port 10: rx pkts=14386485, bytes=10843773932, drop=0, errs=0, frame=0, over=0, crc=0 tx pkts=15666927, bytes=10659584526, drop=0, errs=0, coll=0 port 26: rx pkts=3830, bytes=161388, drop=0, errs=0, frame=0, over=0, crc=0 tx pkts=3025213, bytes=244511981, drop=0, errs=0, coll=0 port 36: rx pkts=16, bytes=1200, drop=0, errs=0, frame=0, over=0, crc=0 tx pkts=898463, bytes=68248745, drop=0, errs=0, coll=0 port 25: rx pkts=4693, bytes=206958, drop=0, errs=0, frame=0, over=0, crc=0 tx pkts=3256605, bytes=264430395, drop=0, errs=0, coll=0 port 35: rx pkts=229447, bytes=21077911, drop=0, errs=0, frame=0, over=0, crc=0 tx pkts=1905393, bytes=758729599, drop=0, errs=0, coll=0 port 28: rx pkts=13, bytes=1074, drop=0, errs=0, frame=0, over=0, crc=0 tx pkts=2266685, bytes=179166266, drop=0, errs=0, coll=0 port 23: rx pkts=10345, bytes=636977, drop=0, errs=0, frame=0, over=0, crc=0 tx pkts=3345437, bytes=272099392, drop=0, errs=0, coll=0 ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:2:4","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"查看bridge的转发表 root@l-network-1:# ovs-appctl fdb/show br-ex port VLAN MAC Age 10 0 fa:16:3e:f8:28:9f 9 11 0 fa:16:3e:a7:d2:f5 8 34 0 fa:16:3e:2f:b2:71 8 4 0 2c:44:fd:89:cf:3a 6 6 0 fa:16:3e:45:c7:c5 5 4 0 fa:16:3e:44:15:eb 5 4 0 2c:44:fd:8a:78:06 4 1 0 fa:16:3e:be:08:35 2 3 0 fa:16:3e:2f:dd:71 1 2 0 fa:16:3e:d7:f0:c1 0 LOCAL 0 2c:44:fd:8a:32:ce 0 4 0 20:0b:c7:37:d0:05 0 ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:2:5","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"设置qos ovs-vsctl set Interface tap0 ingress_policing_rate=100000 ovs-vsctl set Intervace tap ingress_policing_burst=10000 ovs-appctl qos/show \u003ciface\u003e ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:3:0","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"调试技巧 ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:4:0","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"查看流表匹配规则 watch -d -n 1 \"ovs-ofctl dump-flows \u003cbridge\u003e\" ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:4:1","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"查看统计信息 ovs-dpctl show -s ovs-ofctl dump-ports \u003cbr\u003e [port] ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:4:2","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"使用tcpdump抓包,需要设置端口镜像 ip link add name snooper0 type dummy ip link set dev snooper0 up ovs-vsctl add-port br-int snooper0 ovs-vsctl -- set Bridge br-int mirrors=@m -- --id=@snooper0 \\ get Port snooper0 -- --id=@patch-tun get Port patch-tun \\ -- --id=@m create Mirror name=mymirror select-dst-port=@patch-tun \\ select-src-port=@patch-tun output-port=@snooper0 select_all=1 tcpdump -i snooper0 ovs-vsctl clear Bridge br-int mirrors ovs-vsctl del-port br-int snooper0 ip link delete dev snooper0 ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:4:3","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"查看日志 cat /var/log/openvswitch/*.log ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:4:4","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"使用ovs-appctl ofproto/trace {bridge} k1=v1,k2=v2测试流匹配 root@l-network-1:~# ovs-appctl ofproto/trace br-ex in_port=10,dl_src=66:4e:cc:ae:4d:20,dl_dst=46:54:8a:95:dd:f8 -generate Bridge: br-ex Flow: in_port=10,vlan_tci=0x0000,dl_src=66:4e:cc:ae:4d:20,dl_dst=46:54:8a:95:dd:f8,dl_type=0x0000 Rule: table=0 cookie=0 priority=0 OpenFlow actions=NORMAL no learned MAC for destination, flooding Final flow: in_port=10,vlan_tci=0x0000,dl_src=66:4e:cc:ae:4d:20,dl_dst=46:54:8a:95:dd:f8,dl_type=0x0000 Megaflow: in_port=10,vlan_tci=0x0000/0x1fff,dl_src=66:4e:cc:ae:4d:20,dl_dst=46:54:8a:95:dd:f8,dl_type=0x0000 Datapath actions: 27,30,12,14,15,17,20,37,9,28,47,48,54,57,29,25,61,21 ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:4:5","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["openvswitch"],"content":"参考 https://docs.openvswitch.org/en/latest/ http://fishcried.com/2016-02-09/openvswitch-ops-guide/ ","date":"2020-01-01","objectID":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/:5:0","tags":["tool","openvswitch"],"title":"openvswitch 使用速查","uri":"/2020/openvswitch%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5/"},{"categories":["network"],"content":"IPv4地址即将耗尽，工信部要求今年年底三大运营商完成60% IPV4升级IPV6的任务；kubernetes 1.16 已经全面支持 IPv4 和 IPv6 双栈能力，IPv6来势汹汹，不再是光打雷不下雨的光景。作为云计算开发者，学习和掌握IPv6技术势在必行。","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"IPv6 概述 IPv6（互联网协议版本6）是一种新的寻址协议，旨在包含未来互联网的所有可能需求。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:1:0","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"为什么是新的IP版本 到目前为止，IPv4已经证明自己是一个可靠的的可路由寻址协议，并且已经为我们服务了几十年。它是80年代初设计的，可以提供大约2^32个地址，在当时被认为是完全足够的，没想到的是互联网的爆发式增长，把地址已经耗尽。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:1:1","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"为什么不是IPv5 目前为止，Internet协议已经被是被具有IPv4。版本0到3被使用，而协议本身已经正在开发和和实验过程。因此，新协议投入生产前，有许多使用实验协议的后台仍然活跃。协议版本5，我们称为互联网流协议，它使用因特网协议号5来封装其数据报，它从来没有被带入公众使用，但它已经使用。 这里是一个IP版本表及其使用方法: ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:1:2","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"IPv6 特性 IPv6 的设计并不是向后兼容的。IPv6被重新设计。它提供以下功能： 较大的地址空间 简化报头。IPv6将不必要的选项放在报头末尾，使用链表形式，简化了报头。IPv6报头只有IPv4的两倍大。 端到端连接。每个系统都有唯一地址，并且可以通过Internate而不使用NAT。 自动配置。IPv6支持其主机设备的有状态和无状态自动配置模式。这样，没有DHCP服务器不会停止段间通信。 更快转发/路由。 简化头将不必要的的信息放在末尾。包含在报头的第一部分中的信息对于路由器进行路由决定是足够的，从而使得路由决定与查看强制报头一样快。 IPSec。 无广播。IPv6不再支持广播，使用多播和多个主机通信。 任播（anycast）支持。Internet上的多个网口分配相同的任播IP地址。当路由器路由时，发送数据包到最近的目的地。 移动性。IPv6被设计成保持移动性。此功能使主机(如移动电话)在不同的地理区域漫游，并保持与同一IP地址连接。 增强优先级支持。IPv4使用6位DSCP(差分服务代码点)和2位ECN(显式拥塞通知)来提供服务质量，但它只能在端到端设备支持它时使用，即源设备和目的设备 并且底层网络必须支持它。在IPv6中，流量类和流标签用于告诉底层路由器如何有效地处理数据包和路由它。 平稳过渡。IPv6 的大IP地址方案使得设备能够分配具有全球唯一IP地址。此机制保留源IP，不需要NAT。 可扩展性。IPv4 仅提供40字节选项；IPv6的选项可以和IPv6数据包本身大小一样多 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:2:0","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"IPv6 寻址模式 IPv6 支持三种寻址模式： 单播 多播 任播 单播和多播与IPv4差别不大，任播比较少见，这里做下介绍。 IPv6引入了一种新型的寻址，称为Anycast寻址。 在此寻址模式下，多个接口(host)被分配相同的任播IP地址。 当主机希望与配备有任播IP地址的主机通信时，它发送单播消息。 在复杂的路由机制的帮助下，在路由成本方面，该单播消息被递送到最接近发送方的主机。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:3:0","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"IPv6 地址类型和格式 IPv6 使用 128 bit 地址，被划分成8个16位块，每个块转换成由冒号符号分隔的4位十六进制数字。 2001:0000:3238:DFE1:0063:0000:0000:FEFB IPv6 提供了一些规则来缩短地址。规则如下： 规则1 ：丢弃前导0 例如（第5块） 2001:0000:3238:DFE1:63:0000:0000:FEFB 规则2：如果两个或多个块包含连续零，则省略它们并用双冒号::替换。 2001:0000:3238:DFE1:63::FEFB 连续的零块只能被::替换一次。如果地址中仍有零块，它们可以缩小到一个零 2001:0:3238:DFE1:63::FEFB ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:4:0","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"接口ID IPv6 有三种不同类型的单播地址方案。 全局单播地址 链路本地地址 唯一本地地址 地址的后半部分（最后64位）始终用于接口ID。系统的MAC地址由48位组成并以十六进制表示。 MAC地址被认为是在世界范围内唯一分配的。 接口ID利用MAC地址的这种唯一性。 主机可以使用IEEE的扩展唯一标识符(EUI-64)格式自动配置其接口ID。 首先，主机将其自己的MAC地址划分为两个24位的半部分。 然后16位十六进制值0xFFFE被夹在这两个MAC地址的两半之间，产生EUI-64接口ID。 为了将EUI-64 ID转换为IPv6接口标识符，EUI-64 ID的最高有效的第7位(U/L)需要取反。(EUI-64和IPv6该字段含义相反) ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:4:1","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"全局单播地址 此地址类型等同于IPv4的公共地址。IPv6中的全球单播地址是全局可识别和唯一可寻址的。 全局路由前缀:最高有效48位指定为全局路由前缀，分配给特定的自治系统。 全局路由前缀的三个最高有效位始终设置为001。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:4:2","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"链路本地地址 自动配置的IPv6地址称为链路本地地址。 此地址始终以FE80开头。 链路本地地址的前16位总是设置为1111 1110 1000 0000(FE80)。 接下来的48位设置为0，因此: 链路本地地址仅用于链路(广播段)上的IPv6主机之间的通信。 这些地址不可路由，因此路由器不会将这些地址转发到链路之外。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:4:3","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"唯一本地地址 这种类型的IPv6地址是全局唯一的，但它应该用于本地通信。 该地址的后半部分包含接口ID，前半部分被分为前缀，本地位，全局ID和子网ID。 前缀始终设置为1111 110。L位，如果地址是本地分配，则设置为1。 到目前为止，L位到0的含义没有定义。因此，唯一本地IPv6地址始终以“FD\"开头。 IPv6单播地址范围： 链路本地地址的范围仅限于段。 唯一本地地址是本地全局的，但不通过Internet路由，将其范围限制为组织的边界。 全球单播地址是全球唯一和可识别的。 他们应该是互联网v2寻址的本质。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:4:4","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"IPv6 特殊地址 路由协议的保留组播地址 保留路由器/节点的多播地址 这些地址帮助路由器和主机与段上的可用路由器和主机通信，而无需配置IPv6地址。 主机使用基于EUI-64的自动配置来自配置IPv6地址，然后通过这些地址与段上的可用主机/路由器通信。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:5:0","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"IPv6 通信 在 IPv6 中，没有广播机制。启用IPv6的主机不是必须从DHCP获取IP地址，它可以自动配置\u0008自己的IP。ARP协议被ICMPv6邻居发现协议替代。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:6:0","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"地址管理和分配 在IPv6中，主机地址可使用四种方法进行配置： 静态配置—类似于IPv4，主机地址、掩码和网关地址通过人工方式定义。 无状态自动地址配置（SLAAC）—在这种情况下，主机自动配置其地址。启动节点 发送路由器请求消息，申请路由器广播（RA），以配置接口（RFC2462）。 基于状态的DHCPv6—主机使用DHCP获取其IPv6地址。此地址管理类似于IPv4的 DHCP行为（RFC3315）。 无状态DHCP—主机使用SLAAC以及DHCP，来获取其它参数，如TFTP服务器、 WINS等。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:6:1","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"邻居发现协议 邻居发现协议NDP（Neighbor Discovery Protocol）是IPv6协议体系中一个重要的基础协议。邻居发现协议替代了IPv4的ARP（Address Resolution Protocol）和ICMP路由器发现（Router Discovery），它定义了使用ICMPv6报文实现地址解析，跟踪邻居状态，重复地址检测，路由器发现以及重定向等功能。 地址解析 跟踪邻居状态 通过邻居或到达邻居的通信，会因各种原因而中断，包括硬件故障、接口卡的热插入等。如果目的地失效，则恢复是不可能的，通信失败；如果路径失效，则恢复是可能的。因此节点需要维护一张邻居表，每个邻居都有相应的状态，状态之间可以迁移。 RFC2461中定义了5种邻居状态，分别是： 未完成（Incomplete） 可达（Reachable） 陈旧（Stale） 延迟（Delay） 探查（Probe） 重复地址检测 重复地址检测DAD（Duplicate Address Detect）是在接口使用某个IPv6单播地址之前进行的，主要是为了探测是否有其它的节点使用了该地址。尤其是在地址自动配置的时候，进行DAD检测是很必要的。一个IPv6单播地址在分配给一个接口之后且通过重复地址检测之前称为试验地址（Tentative Address）。此时该接口不能使用这个试验地址进行单播通信，但是仍然会加入两个组播组：ALL-NODES组播组和试验地址所对应的Solicited-Node组播组。 IPv6重复地址检测技术和IPv4中的免费ARP类似：节点向试验地址所对应的Solicited-Node组播组发送NS报文。NS报文中目标地址即为该试验地址。如果收到某个其他站点回应的NA报文，就证明该地址已被网络上使用，节点将不能使用该试验地址通讯。 当两端同时检测时情况如下： 若2个节点配置相同地址，同时作重复地址检测时，该地址处于Tentative状态，当一方收到对方发出的DAD NS，则接收方将不启用该地址 一种极端的情况，如果同时收到NS报文，则两端都放弃改地址 路由器发现 路由器发现功能用来发现与本地链路相连的设备，并获取与地址自动配置相关的前缀和其他配置参数。 在IPv6中，IPv6地址可以支持无状态的自动配置，即主机通过某种机制获取网络前缀信息，然后主机自己生成地址的接口标识部分。路由器发现功能是IPv6地址自动配置功能的基础，主要通过以下两种报文实现： 路由器通告RA（Router Advertisement）报文：每台设备为了让二层网络上的主机和设备知道自己的存在，定时都会组播发送RA报文，RA报文中会带有网络前缀信息，及其他一些标志位信息。 路由器请求RS（Router Solicitation）报文：很多情况下主机接入网络后希望尽快获取网络前缀进行通信，此时主机可以立刻发送RS报文，网络上的设备将回应RA报文。 地址自动配置 IPv6地址增长为128位，且终端节点多，对于自动配置的要求更为迫切，除保留了DHCP作为有状态自动配置外，还增加了无状态自动配置。无状态自动配置即自动生成链路本地地址，主机根据RA报文的前缀信息，自动配置全球单播地址等，并获得其他相关信息。 IPv6主机无状态自动配置过程： 根据接口标识产生链路本地地址。 发出邻居请求，进行重复地址检测。 如地址冲突，则停止自动配置，需要手工配置。 如不冲突，链路本地地址生效，节点具备本地链路通信能力。 主机会发送RS报文（或接收到设备定期发送的RA报文）。 根据RA报文中的前缀信息和接口标识得到IPv6地址。 重定向 当网关设备发现报文从其它网关设备转发更好，它就会发送重定向报文告知报文的发送者，让报文发送者选择另一个网关设备。重定向报文也承载在ICMPv6报文中，其Type字段值为137，报文中会携带更好的路径下一跳地址和需要重定向转发的报文的目的地址等信息。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:6:2","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"IPv6 子网划分 在IPv4中，使用网络掩码允许使用借用主机位作为子网位。这导致多个子网，但每个子网的主机较少。 IPv6 地址使用128位来表示，其中16位表示子网划分。地址的后半段（最低有效64位）始终仅用于主机。 在IPv6中，前缀大致相当于IPv4中的子网划分。IPv6前缀由最左边的位构成，起网络标识符的作用。 IPv6规范中为普通IPv6单播地址定义了/64前缀长度。由于IPv6有非常大的地址空间，用户有可能希望使用非/64前缀长度。 在IPv6中，非/64前缀长度将使以下技术失效： 邻居发现（ND） 安全邻居发现（SEND）［RFC3971］ 私密性扩展［RFC4941］ 部分移动IPv6［RFC4866］ 稀疏模式独立组播协议（PIM-SM），带内嵌RP［RFC3956］ 通过IPv6协调支持的站点多重寻址（SHIM6）［SHIM6］ /64前缀 64位前缀适用于网络设备的传统局域网/广域网接口。 /126前缀 126位前缀一般用于点对点链路，类似于IPv4中为点对点链路分配的/30保留地址。但 IPv6的地址空间要远大于IPv4地址空间。一般建议在点对点链路上使用/64。 /127前缀 RFC3627认为，在点对点链路上使用相当于IPv4 /31的/127前缀（RFC 3021），是有害 的。这种分配就像为点对点链路分配/126前缀，使用127前缀是出于考虑地址保留的原 因。为简化运营，应考虑为点对点链路使用/64前缀。 /128前缀 128位前缀可用于需要一个地址的情况。网络设备的回环地址即是这类地址的一个 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:7:0","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"从 IPv4 转变到 IPv6 从 IPv4 到 IPv6 完全转换不太可能，因为 IPv6 不向后兼容。这导致单纯和IPv6站点或IPv4站点无法被跨IP版本访问。 为了克服这种短缺，我们有几种技术可以用来确保从IPv4到IPv6的缓慢而平滑的过渡。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:8:0","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"双栈路由器 路由器可以同时配置IPv4和IPv6地址。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:8:1","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"隧道 在中间路径或中转网络上存在不同IP版本的情况下，隧道提供了更好的解决方案，其中用户的数据可以通过不支持的IP版本。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:8:2","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"NAT协议翻译 这是通过启用NAT-PT（网络地址转换-协议转换）的设备转换到IPv6的另一个重要方法。在NAT-PT的设备的帮助下，实际可以发生在IPv4和IPv6分组之间，反之亦然。见下图： 几乎所有大型企业部署IPv6时都在内部使用双堆栈。双堆栈是学习和获取IPv6地址部署经验的一种简单方法，这对成功迁移非常重要。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:8:3","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"IPv6 路由 路由概念在IPv6的情况下保持相同，但是几乎所有路由协议都被相应的重新定义。 存在两种形式的路由协议： 距离向量路由协议：运行距离向量协议的路由器通告其连接的路由，并从其邻居学习新的路由。RIP和BGP是距离矢量协议。 链路状态路由协议：此协议确认链路的状态，并通告邻居。从对等路由器学习新的路由。在所有路由信息已经收敛之后，链路状态路由协议使用其自己的算法来计算到所有可用链路的最佳路径。OSPF和IS-IS是链路状态路由协议，它们都使用dijkstra的最短路径优先算法。 路由协议可分为两类： 内部路由协议：自治系统或组织内用于在其边界内分发路由。RIP、OSPF 外部路由协议：不同自治系统或组织间发布路由信息。如BGP ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:9:0","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"路由协议 RIPng RIPng 代表下一代路由信息协议。这是一个内部路由协议，是一个距离矢量协议。RIPng已升级支持IPv6 OSPFv3 开放最短路径优先版本3是经过修改以支持IPv6的内部路由协议。 BGPv4 BGPv4是BGP的升级以支持IPv6路由 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:9:1","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"协议更改为支持IPv6 ICMPv6：Internet控制消息协议版本6是ICMP的升级实现，以适应IPv6要求。ICMPv6邻居发现协议替换ARP，并帮助发现链路上的邻居和路由器。 DHCPv6：启用IPv6的主机不需要任何DHCPv6服务器获取IP地址，因为它们可以自动配置。 他们也不需要DHCPv6定位DNS服务器，因为可以通过ICMPv6邻居发现协议发现和配置DNS。 然而DHCPv6服务器可以用于提供这些信息。 DNS：没有新版本的DNS，但它现在配备了扩展，以支持查询IPv6地址。 添加了新的AAAA(quad-A)记录以回复IPv6查询消息。 现在DNS可以用两个IP版本(4和6)回复，而查询格式没有任何改变。 ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:9:2","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"参考资料 https://www.wikiwand.com/en/IPv6_address https://www.cisco.com/c/dam/global/zh_cn/solutions/industry/segment_sol/enterprise/programs_for_large_enterprise/iba/pdf/bn_enterprise_ipv6_addressing_guide_h2cy10.pdf https://www.w3cschool.cn/ipv6/ipv6_overview.html https://www.hi-linux.com/posts/26571.html http://www.what21.com/sys/view/net_ipv6_1536653956137.html https://cshihong.github.io/2018/01/29/IPv6%E9%82%BB%E5%B1%85%E5%8F%91%E7%8E%B0%E5%8D%8F%E8%AE%AE/ ","date":"2019-11-27","objectID":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/:10:0","tags":["network","IPv6"],"title":"IPv6特性介绍","uri":"/2019/ipv6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/"},{"categories":["network"],"content":"最近经常有同事来求助修复容器网络，定位发现大多数网络问题的都是操作系统的网络配置被修改导致的，本文记录下这些常见配置问题，并本着程序员的偷懒精神，在文末提供检测脚本。","date":"2019-11-24","objectID":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/","tags":["network","tools"],"title":"常见容器网络问题诊断","uri":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/"},{"categories":["network"],"content":"Kubernetes 的容器网络插件家族越来越庞大，各种模式层出不穷，但是万变不离其宗，overlay 和 underlay。overlay 常使用 vxlan 或者 ipip，underlay 使用 host-gw、bgp，或者结合云厂商提供的底层路由，如：vpc router，virtual switch；还有一类underlay 是目前各大云厂商主推的 eni（Elastic Network Interface）模式，将本来虚拟机使用的网卡插入到容器使用，使容器网络和虚拟机网络一样成为一等公民，拥有相同的网络访问权限，这个场景下容器网络被极度简化，大部分功能都由公有云虚拟机网络完成。 容器网络发展到现在，基本的组网方式已经十分成熟，抛开负载的性能优化问题不谈，网络功能问题的根因定位已经没多少新花样了，下面我就介绍下我在工作中使用的三板斧。 ","date":"2019-11-24","objectID":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/:0:0","tags":["network","tools"],"title":"常见容器网络问题诊断","uri":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/"},{"categories":["network"],"content":"系统配置 系统配置被修改导致网络行为改变，容器网络故障是最常出现的。 ","date":"2019-11-24","objectID":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/:1:0","tags":["network","tools"],"title":"常见容器网络问题诊断","uri":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/"},{"categories":["network"],"content":"sysctl net.ipv4.ip_forward（需要打开） net.ipv4.conf.{all,interface}.rp_filter（非对称路由环境设置为0或2） net.ipv4.tcp_tw_recycle（NAT环境关闭） net.ipv4.tcp_tw_reuse net.ipv4.ip_forward 控制主机是否允许转发数据报文，该值一般是 1，为0时常常导致容器访问service失败。 net.ipv4.conf.all.rp_filter 控制系统是否开启对数据包源地址的校验。先看下文档中的介绍： rp_filter - INTEGER 0 - No source validation. 1 - Strict mode as defined in RFC3704 Strict Reverse Path Each incoming packet is tested against the FIB and if the interface is not the best reverse path the packet check will fail. By default failed packets are discarded. 2 - Loose mode as defined in RFC3704 Loose Reverse Path Each incoming packet's source address is also tested against the FIB and if the source address is not reachable via any interface the packet check will fail. Current recommended practice in RFC3704 is to enable strict mode to prevent IP spoofing from DDos attacks. If using asymmetric routing or other complicated routing, then loose mode is recommended. The max value from conf/{all,interface}/rp_filter is used when doing source validation on the {interface}. Default value is 0. Note that some distributions enable itin startup scripts. 即rp_filter参数有三个值，0，1，2，具体含义： 0: 不开启源地址校验 1: 开启严格的反向路径校验，对每个进来的包，校验其反向路径是否最佳。如果不是最佳，则丢弃该数据包 2: 开启松散的反向路径校验。对每个进来的包，校验其反向源地址是否可达（通过任意网口），如果不可达，则丢弃该数据包。 容器网络假如使用了非对称路由，rp_filter 一定要设置成2或者0. net.ipv4.tcp_tw_recycle 参数是为了服务端快速回收 TIME_WAIT 状态的 sockets 设置的，一些网络调优的文档可能会提到设置这个参数，但是该参数并不建议在 NAT(Network Address Translation) 环境中使用。 TCP 为了避免序列号反转的问题，使用时间戳（非标准时间，只是一个计数器）识别过时的报文并丢弃，即 PAWS(PROTECT AGAINST WRAPPED SEQUENCE NUMBERS )。默认PAWS是针对单个连接的，如果开启了 net.ipv4.tcp_tw_recycle ，为了解决重用 TIME_WAIT 导致的前一个连接发来的数据包在新连接中被当成有效数据包处理，Per-Connection 被升级成了 Per-Host。在SNAT环境中，来自不同HOST的连接被当成来自同一个HOST，导致时间戳数字小的友军会被系统误认为是过时报文丢弃。 该参数在 Linux 4.1 内核中已经移除 net.ipv4.tcp_tw_reuse 和上一个 net.ipv4.tcp_tw_recycle 功能类似，主要用于客户端快速回收 TIME_WAIT 状态的 port 重用。该参数当前还没有发现明显的问题，打不开开都可以。 ","date":"2019-11-24","objectID":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/:1:1","tags":["network","tools"],"title":"常见容器网络问题诊断","uri":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/"},{"categories":["network"],"content":"iptables iptalbes –policy FORWARD ACCEPT DROP SNAT 数据包经过主机时第二道关口一般是 iptables，常常 tcpdump 抓到了数据包，但是应用就是没有收到，这个时候很可能是 iptables 把数据包过滤了。 大多数容器网络需要iptables默认接受数据包转发，即设置：iptables --policy FORWARD ACCEPT。 这个可以用 iptables -nvL FORWARD 查看当前默认规则。 iptables 还有其他规则可能导致丢包，使用 iptables -nvL ｜ grep DROP 查看丢包统计。 除了丢包，错误的处理 SNAT 也可能导致容器网络访问外网失败，可以查看 iptables 的 SNAT 规则，并在主机上抓包确认。 ","date":"2019-11-24","objectID":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/:1:2","tags":["network","tools"],"title":"常见容器网络问题诊断","uri":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/"},{"categories":["network"],"content":"route default route ip rule 如果容器访问某个ip报错 no route to host，这个时候自然要查看下路由了。不光要排查容器内部，还要排查报文经过路径上的路由，并且需要注意 iptables 的 DNAT 规则改写目的ip，以及 ip rule 的 route table 查找规则。 ","date":"2019-11-24","objectID":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/:1:3","tags":["network","tools"],"title":"常见容器网络问题诊断","uri":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/"},{"categories":["network"],"content":"定位工具 当我们排查了一遍系统参数还没有头绪的时候，这个时候就该网络调试工具上场了。 tcpdump wireshark netstat/ss iptables lsof – p PID 使用 tcpdump 抓包是网络问题排查的常见手段。 tcpdump -i eth0 tcp host 192.168.4.3 and port 4789 -ne 也可以将抓到的包信息写入文件放到 wireshark 中分析，可以得到更全面的信息。 tcpdump -i eth0 tcp host 192.168.4.3 -w packet.pcap netstat 或 ss 命令用来查看当前连接统计信息，可以分析连接失败的原因。 iptables 需要排查规则是否符合期望，具体使用可以参见 iptables快速入门 lsof 可以用来查看进程占用的句柄数，有时候新的连接无法建立，可能是程序句柄泄露或者最大值设置太小（ulimits -a查看） ","date":"2019-11-24","objectID":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/:2:0","tags":["network","tools"],"title":"常见容器网络问题诊断","uri":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/"},{"categories":["network"],"content":"配置扫描脚本 ## green to echo function green(){ echo -e \"\\033[32m[ $1]\\033[0m\" } containerID=$1 green kernel: `uname -r` green cni.conf cat /etc/cni/net.d/cni.conf green IP in container: docker exec -ti $containerID ip a s green Route in container: docker exec -ti $containerID ip r s green rp_filter in container: docker exec -ti $containerID sysctl -a|grep rp_filter green route in host: ip r s green ip rule in host: ip rule green ip forward in host: sysctl sysctl net.ipv4.ip_forward iptables -nvL|grep FORWARD green rp_filter in host: sysctl -a|grep rp_filter green tcp_tw_recycle in host: sysctl net.ipv4.tcp_tw_recycle ","date":"2019-11-24","objectID":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/:3:0","tags":["network","tools"],"title":"常见容器网络问题诊断","uri":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/"},{"categories":["network"],"content":"参考资料 https://computingforgeeks.com/netstat-vs-ss-usage-guide-linux/ ","date":"2019-11-24","objectID":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/:4:0","tags":["network","tools"],"title":"常见容器网络问题诊断","uri":"/2019/%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%AF%8A%E6%96%AD/"},{"categories":["kubernetes"],"content":"Kuberentes 已经成为云计算事实上的基础设施，各大云服务厂商都推出了自己的Kubernets 集群托管服务。处于信息安全考虑，一些企业不允许自己的核心资产暴露在公共服务器上，公有云并不适合他们。一些云服务厂商嗅到了其中的商机，国外大厂OpenShift，国内云厂商阿里云、华为云、青云等纷纷顺势推出了基于Kubernetes的私有集群以及混合云的解决方案。 企业在选型方案是，网络能力往往是考量各解决方案优劣的一个重要指标，但是本文并不打算分析各厂商的网络方案（工作量太大，计划后续补上），而是主要聚焦 Kubernetes 集群中的一个小的网络特性，即 Kubernetes Load Balance Service 如何保留客户端源IP。 ","date":"2019-09-04","objectID":"/2019/preserve-source-ip-in-k8s/:0:0","tags":["kubernetes","network"],"title":"Load Balance 访问 Kubernetes Pod 源 IP 保留方案探索","uri":"/2019/preserve-source-ip-in-k8s/"},{"categories":["kubernetes"],"content":"现状 Kuberntes 的 Service Type 分为三种1： Cluster IP NodePort LoadBalancer 以下我们基于 kube-proxy 的 iptables 模式或 ipvs 模式进行分析，不考虑 userspace 模式。 Type=ClusterIP 的 Service 一般只支持集群内部访问，通过 iptables 规则或者 ipvs 规则完成 ClusterIP 到 Pod IP的转换，Kubernetes只对访问ClusterIP的流量进行DNAT，并不会进行SNAT，但是实际集群是否会进行 SNAT 还要看CNI网络插件实现，像calico、flannel等，流量必须经过主机网络空间的容器网络实现，并不需要进行SNAT，而一些基于IPVlan，VLAN，将网络直接接入容器的实现，则需要进行SNAT，保证回程流量能够经过主机网络空间，实现NAT转换。大致流量如图： Type=NodePort 的 Service 支持集群外访问，客户端通过访问节点的端口，在节点内通 过iptables 或ipvs 规则转发流量实现负载均衡，该模式下Kubernetes除了会对流量进行DNAT，还会进行SNAT，这是为了保证负载均衡到其他节点的流量能够回到该节点，进行NAT解除操作。可能有的用户不想要在节点上再进行一次负载均衡，并且想要保留 client ip，Kubernetes 很贴心的支持了这个选项，Service service.spec.externalTrafficPolicy 字段设置成 Local 后，访问NodePort的流量就不再进行SNAT和负载均衡了。 Type=LoadBalance 的 Service 默认开启 SNAT，因为所有的 Ready 节点都是 LB 的后端，如果数据报文到了一个没有 endpoint 的节点，系统需要将该报文转发到其他节点。 如果是在 Google Kubernetes Engine/GCE，同样的设置service.spec.externalTrafficPolicy 为 Local 可以让没有endpoint 的节点 service 健康检查失败，移除LB后端，kubernetes不会将流量转发到其他节点，也就不再需要进行 SNAT，保留了源 IP。 client | lb VIP / ^ v / health check ---\u003e node 1 node 2 \u003c--- health check 200 \u003c--- ^ | ---\u003e 500 | V endpoint ","date":"2019-09-04","objectID":"/2019/preserve-source-ip-in-k8s/:1:0","tags":["kubernetes","network"],"title":"Load Balance 访问 Kubernetes Pod 源 IP 保留方案探索","uri":"/2019/preserve-source-ip-in-k8s/"},{"categories":["kubernetes"],"content":"LoadBalancer 保留源 IP LoadBalancer的工作模式有两种： 作为代理，接收来自客户端的请求，同时建立新的连接请求，和后端服务器建立连接。这种情况下，后端服务器看到的源IP是LB的IP。 作为数据包转发器，客户端访问 LB 的 VIP，最终保持源IP和后端服务器建立连接。 第一种模式的LB需要依赖协议通知客户端真实的源IP，例如 HTTP 的 X-FORWARD-FOR，或者proxy protocol。第二种模式天然保留了源IP，但是在kubernetes中，需要配合关闭SNAT，保留源IP进入Pod，同时service.spec.healthCheckNodePort可以帮助LB检测节点上是否存在endpoint，剔除不合格的node。 ","date":"2019-09-04","objectID":"/2019/preserve-source-ip-in-k8s/:2:0","tags":["kubernetes","network"],"title":"Load Balance 访问 Kubernetes Pod 源 IP 保留方案探索","uri":"/2019/preserve-source-ip-in-k8s/"},{"categories":["kubernetes"],"content":"Direct Route Direct Route模式即LB作为路由器角色，将客户端的流量直接负载均衡，路由到后端节点，也就是上面提到的工作模式2. DR 模式有几个限制2： VIP 的端口必须和RS服务的端口一致（DR模式只修改包的 mac 地址，不会修改IP及上层的内容） RS 必须对 arp 做相关设置，lo 接口需要绑定VIP（使用iptables进行DNAT处理也是可行的3） VIP 和 RIP 不需要在同一个网段，但是 Director 要有一个网口和 RS 是再同一个物理网络下 支持该模式的开源方案有LVS和HAPROXY。 LVS Haproxy kubernetes Kubernetes 可以利用这两个组件实现 DR 模式源IP保留。 ","date":"2019-09-04","objectID":"/2019/preserve-source-ip-in-k8s/:2:1","tags":["kubernetes","network"],"title":"Load Balance 访问 Kubernetes Pod 源 IP 保留方案探索","uri":"/2019/preserve-source-ip-in-k8s/"},{"categories":["kubernetes"],"content":"PROXY Protocol PROXY Protocol 是HAProxy作者提出的一个协议4，通过在数据流前端加入一小段协议报文，实现源IP透传。该协议要求有 sender 和 receiver，两者需要匹配 proxy protocol，否则数据流解析就会有问题。目前已经有很多开源软件加入支持该协议，因此通过部署支持该协议的LB，如F5，以及在容器中加入支持proxy protocol的sidecar，例如nginx，envoy，可以实现源IP透传。 ","date":"2019-09-04","objectID":"/2019/preserve-source-ip-in-k8s/:2:2","tags":["kubernetes","network"],"title":"Load Balance 访问 Kubernetes Pod 源 IP 保留方案探索","uri":"/2019/preserve-source-ip-in-k8s/"},{"categories":["kubernetes"],"content":"TOA TOA是一个内核模块，通过在TCP包中添加一个OPTION来传递客户端的源IP5。LB需要支持在TCP报文中插入该OPTION，节点通过安装TOA模块，修改getpeername()系统调用，让Pod内应用通过getpeername()获取到真实的源IP。 https://kubernetes.io/docs/tutorials/services/source-ip/  ↩︎ http://linbo.github.io/2017/08/20/lvs-dr  ↩︎ https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/load_balancer_administration/s1-lvs-direct-vsa  ↩︎ https://www.haproxy.com/blog/haproxy/proxy-protocol/  ↩︎ http://www.just4coding.com/blog/2015/11/16/toa/  ↩︎ ","date":"2019-09-04","objectID":"/2019/preserve-source-ip-in-k8s/:2:3","tags":["kubernetes","network"],"title":"Load Balance 访问 Kubernetes Pod 源 IP 保留方案探索","uri":"/2019/preserve-source-ip-in-k8s/"},{"categories":["network"],"content":"iptables 大杂烩，从概念到例子一应俱全，帮助快速学会iptables的使用。","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"iptables 是 netfilter 项目的一部分，自1998年首发至今已经20年了，仍然是Linux中网络流量控制的重要软件。学习网络知识，iptables 是绕不过的一道坎。不论是配置网络防火墙，NAT，IP流量转发，使用iptables都可以实现。 介绍iptables的文章已经有很多，在这里我再炒一遍冷饭，为的是把已有的资料糅合在一起，方便能在一篇文章里找到需要的知识。 ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:0:0","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"基本概念 iptables 可以检测、修改、转发、重定向和丢弃IPv4数据包。过滤IPv4数据包的代码已经内置在内核中，并且按照不同的目的被组织成 表 的集合。 表 由一组预先定义的 链 组成，链 包含便利顺序规则。每一条规则包含一个谓词的潜在匹配和相应的动作（称为 目标），如果谓词为真，该动作会被执行。这就是条件匹配。iptables 是用户工具，允许用户使用 链 和 规则。链 和 规则 能组合成非常复杂的Linux IP 路由规则，新手面对这些规则时可能会感到气馁，但是，实际上最常用的一些应用案例（NAT或者基本网络防火墙）并不是很复杂。 理解iptables如果工作的关键是下面这张图。 从任何网络端口进来的每一个IP数据包都要从上到下穿过这张图。一种常见的困扰是认为iptables对从内部端口进入的数据包和从面向互联网端口进入的数据包采用不同的处理方式，相反，iptables对从任何端口进入的数据包都会采用相同的处理方式。可以定义规则使iptables采取不同的方式对待从不同端口进入的数据包。 这张图里的顺序有点复杂，我把它拆成两组顺序关系：表 的顺序和 链 的顺序。 表的顺序： raw -\u003e mangle -\u003e nat -\u003e filter 链的顺序： ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:1:0","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"表（Tables） iptables 包含5张表 raw 用于配置数据包，raw 中的数据包不会被系统跟踪 filter 是用于存放所有与防火墙相关操作的默认表 nat 用于网络地址转换 mangle 用于对特定数据包的修改 security 用于强制访问控制（例如：SELinux） 大部分情况仅需要使用 filter 和 nat 。其他表用于更复杂的情况——包括多路由和路由判定。 ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:1:1","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"链（Chains） 表由链组成，链是一些安装顺序排列的规则和列表。默认的 filter 表包含 INPUT，OUTPUT 和 FORWARD 3 条内建链。 nat 表包含 PREROUTING, POSTROUTING 和 OUTPUT 链。 ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:1:2","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"规则（Rules） 数据包的过滤基于 规则。规则由一个目标（数据包包匹配所有条件后的动作）和很多匹配（导致该规则可以应用的数据包所满足的条件）指定。一个规则的典型匹配事项是数据包进入的端口（例如： eth0或者eth1）、数据包的类型（ICMP，TCP或者UDP）和数据包的目的端口。 目标使用 -j 或者 --jump 选项指定。目标是可以用户定义的链、一个内置的特定目标或者是一个目标扩展。内置目标有 ACCEPT,DROP,QUEUE和RETURN,目标扩展是REJECT和LOG。如果目标是内置目标，数据包的命运立刻被决定并且在当前表的数据包处理过程会停止。如果目标用户定义的链，并且数据包成功穿过第二条链，目标将移动到原始链中的下一个规则。目标扩展可以被终止（像内置目标一样）或者不终止（像用户定义链一样）。 ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:1:3","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"遍历链（Traversing Chains） 上述流程图描述了在任何接口上收到的网络数据包是按照怎样的顺序走过表的交通管制链。第一个路由策略包决定数据包的目的地址是本地主机（这时穿过 INPUT 链），还是其他主机（穿过FORWARD链）;中间的路由策略决定传出的包使用哪个源地址、分配哪个接口；最后一个路由策略存在是因为先前的 mangle 与 nat 链可能会改变数据包的路由信息。数据包通过路径上的每一条链时，链中的每一条规则按顺序匹配；无论何时匹配了一条规则，相应的 target/jump 动作将会执行。最常用的 3 个 taget 是 ACCPET , DROP 或者 jump 到自定义链。内置的链有默认的策略，但是用户自定义的链没有默认策略。在jump到的链中，若每条规则都不能完全匹配，那么数据包像下图一样返回到调用链。 DROP target 的规则完全能匹配，那么被匹配的数据包会被丢弃。如果一个数据包在链中被 ACCEPT，那么他会被所有的父链 ACCEPT。并且不在便利其他父链。然而，要注意的是，数据包还会以正常的方式继续遍历其他表中的其他链。 REJECT 拦阻该数据包，并返回数据包通知对方，可以返回的数据包有几个选择：ICMP port-unreachable、ICMP echo-reply 或者是 tcp-reset（这个数据包会要求对方变比连接），进行完此处理动作后，不再对比其他规则，直接中断过滤程序。范例如下： iptables -A INPUT -p TCP --dport 22 -j REJECT --reject-with ICMP echo-reply REDIRECT 将封包重新导向另一个端口（PNAT），进行完此动作后，将会继续对比其他规则。这个动作可以用来实现透明代理或者保护web服务器。例如： iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT--to-ports 8081 MASQUERADE 改写封包来源IP为防火墙的IP，可以指定port对应的范围，进行完此处理动作后，直接跳往下一个规则链(mangle:postrouting)。这个功能与 SNAT 略有不同，当进行IP伪装时，不需要指定为装成哪个IP，IP会从网卡直接读取，当使用拨接连线时，IP通常是由ISP公司的DHCP服务器指派的，这个时候 MASQUERADE 特别有用，范例如下: iptables -t nat -A POSTROUTING -p TCP -j MASQUERADE --to-ports 21000-31000 LOG 将数据包相关信息记录在 /var/log 中，详细位置请查阅 /etc/syslog/conf 配置文件，进行完此处理动作后，将会继续对比其他规则。例如： iptables -A INPUT -p tcp -j LOG --log-prefix \"input packet\" SNAT 改写封包来源为某特定IP或IP范围，可以指定port对应的范围，进行完此处理动作后，将直接跳往下一规则链（mangle:postrouting）。范例如下： iptables -t nat -A POSTROUTING -p tcp -o eth0 -j SNAT --to-source 192.168.10.15-192.168.10.160:2100-3200 DNAT 改写数据包包目的地IP为某特定IP或IP范围，可以指定port对应的范围，进行完此处理动作后，将会直接跳往下一规则链（filter:input或filter:forward) iptables -t nat -A PREROUTING -p tcp -d 15.45.23.67 --dport 80 -j DNAT --to-destination 192.168.10.1-192.168.10.10:80-100 MIRROR 镜像数据包，也就是将来源IP与目的IP对调后，将数据包返回，进行完此处理动作后将会中断过滤程序。 QUEUE 中断过滤程序，将封包放入队列，交给其他程序处理。透过自行开发的处理程序，可以进行其他应用，例如：计算联机费用……等。 RETURN 结束在目前规则链中的处理程序，返回父规则链中继续过滤。 MARK 将封包打上某个代号，以便提供作为后续过滤的条件判断依据，尽享完此处理动作后，将会继续对比其他规则，范例如下： iptables -t mangle -A PREROUTING -p tcp --dport 22 -j MARK --set-mark 22 ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:1:4","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"模块 有许多模块可以用来扩展 iptables，例如 connlimit， conntrack，limit和recent。这些模块增添了功能，可以进行更复杂的过滤。 ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:1:5","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"配置并运行 iptables iptables 是一个 systemd 服务，因此可以这样启动： # systemctl start iptables 但是，除非有 /etc/iptables/iptables.rules 否则服务不会启动。因此第一次启动服务时如果没有该文件，使用以下命令创建： # touch /etc/iptables/iptables.rules ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:2:0","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"命令行 显示当前规则 # iptables -nvL ----------------------------------------------------- Chain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0K packets, 0 bytes) pkts bytes target prot opt in out source destination 添加 --line-numbers 选项可以显示行号，插入规则是有用。 重置规则 使用这些命令刷新和重置iptalbes到默认状态： # iptables -F # iptables -X # iptables -t nat -F # iptables -t nat -X # iptables -t mangle -F # iptables -t mangle -X # iptables -t raw -F # iptables -t raw -X # iptables -t security -F # iptables -t security -X # iptables -P INPUT ACCEPT # iptables -P FORWARD ACCEPT # iptables -P OUTPUT ACCEPT 没有任何参数的 -F 命令在当前表中刷新所有链。同样的, -X 命令删除表中所有非默认链。 编辑规则 有两种添加规则的方式，一种是在链上附加规则，另一种是将规则插入到链上的某个特定位置。 让计算机禁止转发数据包，将 FORWARD 链默认的路由规则由 ACCEPT 改成 DROP。 # iptables -P FORWARD DROP Dropbox 的局域网同步特性，每30s广播数据包到所有可视的计算机，如果我们碰巧在一个拥有Dropbox客户端的局域网中，但是我们不想使用这个特性，那么我们希望拒绝这些数据包。 # iptables -A INPUT -p tcp --dport 17500 -j REJECT --reject-with icmp-port-unreachable # iptables -nvL --line-numbers ------------------------------------------------------------------ Chain INPUT (policy ACCEPT 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination 1 0 0 REJECT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:17500 reject-with icmp-port-unreachable Chain FORWARD (policy DROP 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination 现在我们希望安装Dropbox，也希望局域网同步，但是我们的网络只有一个特定的IP地址，因此需要使用 -R 参数来替换旧规则，只接收特定IP地址的广播包，10.0.0.85是我们另一个IP地址。 # iptables -R INPUT 1 -p tcp --dport 17500 ! -s 10.0.0.85 -j REJECT --reject-with icmp-port-unreachable # iptables -nvL --line-numbers ------------------------------------------------------------------- Chain INPUT (policy ACCEPT 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination 1 0 0 REJECT tcp -- * * !10.0.0.85 0.0.0.0/0 tcp dpt:17500 reject-with icmp-port-unreachable Chain FORWARD (policy DROP 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination 我们现在允许 10.0.0.85 访问计算机 17500 端口，但是这条规则不可升级，如果有友好的Dropbox用户想要访问设备上的 ‘17500’ 端口，我们应该马上允许，而不是在测试过所有防火墙规则后再允许。 因此我们在旧规则前插入一条新规则： # iptables -I INPUT -p tcp --dport 17500 -s 10.0.0.85 -j ACCEPT -m comment --comment \"Friendly Dropbox\" # iptables -nvL --line-numbers ------------------------------------------------------------------- Chain INPUT (policy ACCEPT 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination 1 0 0 ACCEPT tcp -- * * 10.0.0.85 0.0.0.0/0 tcp dpt:17500 /* Friendly Dropbox */ 2 0 0 REJECT tcp -- * * !10.0.0.85 0.0.0.0/0 tcp dpt:17500 reject-with icmp-port-unreachable Chain FORWARD (policy DROP 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination 改变第二条规则，使其拒绝17500端口的任何数据包： # iptables -R INPUT 2 -p tcp --dport 17500 -j REJECT --reject-with icmp-port-unreachable # iptables -nvL --line-numbers ------------------------------------------------------------------- Chain INPUT (policy ACCEPT 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination 1 0 0 ACCEPT tcp -- * * 10.0.0.85 0.0.0.0/0 tcp dpt:17500 /* Friendly Dropbox */ 2 0 0 REJECT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:17500 reject-with icmp-port-unreachable Chain FORWARD (policy DROP 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination 保存规则 通过命令行添加规则，规则文件不会自动改变，必须手动保存： # iptables-save \u003e /etc/iptables/iptables.rules 修改配置文件后，需要重新加载服务： # systemctl reload iptables 或者通过iptables直接加载： # iptables-restore \u003c /etc/iptables","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:2:1","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"日志 LOG 目标可以来记录匹配某个规则的数据包。和ACCEPT或DROP规则不同，进入LOG目标之后数据包会继续沿着链往下走。所以要记录所有丢弃的数据包，只需要在DROP规则前加上相应的LOG规则。但是这样会比较复杂，影响效率，所以应该创建一个logdrop链。 # iptables -N logdrop # iptables -A logdrop -m limit --limit 5/m --limit-burst 10 -j LOG # iptables -A logdrop -j DROP 现在任何时候想要丢弃数据包并且记录该事件，只要跳转到logdrop链，例如： # iptables -A INPUT -m conntrack --ctstate INVALID -j logdrop ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:3:0","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"限制日志级别 上述 ’logdrop’ 链使用限制(limit)模式来防止iptables日志过大造成不必要的硬盘读写。 限制模式使用 -m limit，可以使用 --limit 来设置平均速率或者使用 --limit-brust 来设置起始触发速率。在上述 logdrop 里，添加一条记录所有通过其数据包的规则，开始的连续10个数据包将被记录，之后的每分钟只会记录5个数据包。 ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:3:1","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"查看记录的数据包 记录的数据包作为内核信息，可以在 systemd journal看到，使用以下命令查看所有最近一次启动后所记录的数据包： # journalctl -k | grep \"IN=.*OUT=.*\" | less ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:3:2","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"ulogd ulogd 是专门用于netfilter的日志工具，可以替代默认的LOG目标。 ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:3:3","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"FAQ ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:4:0","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"tcpdump 可以抓到包，但是程序接收不到 tcpdump在进入iptables之前抓包，所有有可能数据包被iptables丢弃了。 ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:4:1","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["network"],"content":"参考资料 https://wiki.archlinux.org/index.php/Iptables_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87) https://www.jianshu.com/p/6d77d73325bf ","date":"2019-03-16","objectID":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/:5:0","tags":["network","iptables"],"title":"iptables 快速入门","uri":"/2019/iptables%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"categories":["kubernetes"],"content":"添加一个新 API Version 如果你要为一个 Group 添加一个新的 API Version，你可以从 pkg/apis/\u003cgroup\u003e/\u003cexisting-version\u003e copy 到 staging/src/k8s.io/api/\u003cgroup\u003e/\u003cexisting-version\u003e 目录中。 由于项目在飞速迭代，以下的内容有可能已经过时： 你可以通过修改pkg/master/master.go. 控制是否默认 API Version enable 你必须在pkg/apis/group_name/install/install.go. 中添加新 version 你必须在hack/lib/init.sh#KUBE_AVAILABLE_GROUP_VERSIONS. 中添加新version 你必须在hack/update-generated-protobuf-dockerized.sh 中添加新version，帮助生成protobuf IDL和marshallers 你必须在cmd/kube-apiserver/app#apiVersionPriorities 你必须为新version安装storage pkg/registry/group_name/rest ","date":"2018-12-26","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/:1:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（五）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/"},{"categories":["kubernetes"],"content":"添加一个新 API Group 你需要在 pkg/apis 和 staging/src/k8s.io/api 中为 Group 创建新的目录。复制已有的 API Group 的目录结构，例如：pkg/apis/authentication 和 staging/src/k8s.io/api/authentication；用自己的 group 名替换 authentication，用自己的 version 替换旧的 version。替换 versioned 和 internal 中 register.go 的 API Kinds，还有 install.go 中的 kinds (1.11版本后 install.go 不再需要修改kind) 你需要在代码中一些未知加入你的 API Group/Verison，并且参考 添加一个新 API Version 段落，需要重新生成前面提到的代码。 ","date":"2018-12-26","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/:2:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（五）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/"},{"categories":["kubernetes"],"content":"更新 fuzzer 测试APIs的相互转换稳定性的一个方法是\"fuzz\"（填充随机值）到 API 对象中，并且把它们在不同版本的API间进行转换。这个一个很好的方法，能够暴露代码中丢失的信息和错误的假设前提。如果你添加了任意字段需要很好的格式化（测试不进行validation），或者你假设 slice 至少包含一个元素，你可能会得到 serialization_test 的错误返回。如果遇到了这类问题，你可以自定义 fuzz 方法满足要求。 fuzzer 可以在 pkg/api/testing/fuzzer.go 中找到。 ","date":"2018-12-26","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/:3:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（五）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/"},{"categories":["kubernetes"],"content":"更新语义比较 非常非常少见的情况，但是还是简单说明。某些更新了 boject 的内容，用了不同的表达方式，但是又想要比较函数在比较旧的表达方式和新的表达方式时，能够通过语义进行对比。例如二进制格式化的10和十进制格式化的2语义上时相同的。Go 唯一支持的 Deep-Equal 是一个字段一个字段进行比特比较。 首先你不应该这么做，如果不可避免，你需要了解 apiequality.Semantic.DeepEqual routine，它支持自定义指定类型——　可以在pkg/api/helper/helpers.go 中找 还有一件事你可能需要了解：unexported field. Go 的 relect 包支持 unexported fields。但是我们不支持——apiequality.Semantic.DeepEqual. 幸运的时大部分 API Object 导出了所有的 fields. 但是有时你想要不导出字段（time.Time包含未导出字段），你可能需要在 apiequality.Semantic.DeepEqual 自定义函数。 ","date":"2018-12-26","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/:4:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（五）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/"},{"categories":["kubernetes"],"content":"实现你的修改 到这里你已经完成了 API 的修改，接下来就是完成代码的实现。 ","date":"2018-12-26","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/:5:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（五）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/"},{"categories":["kubernetes"],"content":"编写 end-to-end tests 看以看这篇 e2e doc 文档学习如何为你的特性编写 end-to-end test。 ","date":"2018-12-26","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/:6:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（五）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/"},{"categories":["kubernetes"],"content":"Example 和 docs 在最后，你通过了单元测试、e2e测试，但是还没有结束。你只是修改了 API，如果你修改了已存在的 API， 你必须要确定所有的例子和文档也同时更新。这其实很困难，尤其时在JSON和YAML中会默默丢弃未知的字段。你可以使用 grep 和 ack 来辅助。 如果你添加了功能，你需要考虑添加文档和例子： 通过运行以下脚本确认你跟个新了 swagger 和 OpenAPI spec： hack/update-swagger-spec.sh hack/update-openapi-spec.sh API spec 的修改 commit 应该和其他的修改分开。 ","date":"2018-12-26","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/:7:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（五）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/"},{"categories":["kubernetes"],"content":"参考 https://github.com/kubernetes/community/blob/master/contributors/devel/api_changes.md#making-a-new-api-version ","date":"2018-12-26","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/:8:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（五）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%94/"},{"categories":["golang"],"content":"前言 这两天升级 client-go 版本，涉及 grpc proto 相关代码生成。升级完成后在调试的过程中，发现当数据存入etcd时，一个boolean类型的字段消失了，仔细研究了相关代码半天，最后才发现 go 在 Marshal 结构体时，如果字段是boolean类型，并且设置了omitempty，则会在false的事后作为empty删除。为了避免以后再次栽倒同样的坑里，特意写作本篇博客详细记录golang对json的处理。 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:1:0","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"golang 标签（tag）系统 在 golang 中，命名都推荐驼峰方式，并且首字母大小写有特殊语法含义：结构体中首字母小写外包无法引用。但是由于经常需要和其他系统进行数据交互，例如转换成 json 格式，存储到 mongodb 等等。这个时候如果用属性名作为键值可能不符合项目要求。 所以 golang 支持 `` 定义标签（tag），在转换成其他格式的时候，会使用其中特定的字段作为键值。例如： type User struct { UserId int `json:\"user_id\" bson:\"user_id\"` UserName string `json:\"user_name\" bson:\"user_name\"` } u := \u0026User{UserId: 1, UserName: \"tony\"} j, _ := json.Marshal(u) fmt.Println(string(j)) // 输出内容：{\"user_id\":1,\"user_name\":\"tony\"} 如果没有定义标签，则输出： {\"UserId\":1,\"UserName\":\"tony\"} 可以看到直接使用了struct的属性名作为键值。 其中还有一个 bson 的声明，这个是用在数据存储到 mongodb 使用的。 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:2:0","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"struct 成员变量标签 （Tag） 获取 开发者也可以通过 golang 提供的方法获取 Tag 内容，利用 Tag 进行开发。 如何获取呢，可以使用反射包（reflect）中的方法获取： t := reflect.TypeOf(u) field := t.Elem().Field(0) fmt.Println(field.Tag.Get(\"json\")) fmt.Println(field.Tag.Get(\"bson\")) json package 和 mongodb package 等包就是利用了标签系统完成数据交换。 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:2:1","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"json 处理流程 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:3:0","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"Encoding 编码json使用 Marshal 方法 func Marshal(v interface{}) ([]byte, error) Go 结构体 Message type Message struct { Name string Body string Time int64 } 实例 m := Message{\"Alice\", \"Hello\", 1294706395881547000} 我们可以使用 json.Marshal 来获取 JSON-encoded data b, err := json.Marshal(m) b == []byte(`{\"Name\":\"Alice\",\"Body\":\"Hello\",\"Time\":1294706395881547000}`) 只有能够被json正常表示的数据结构才能够完成编码： JSON 对象只支持 string 作为 key；因此支持的 Go map 类型必须是 map[string]T（T是json package支持的类型） Channel，complex，和 function 类型不支持编码 Pointer 会按照指向的值进行编码（如果pointer时nil，则编码成‘null’） json package 只编码 exported filed（也就是大写字母开头的字段）。因此只有导出的字段出现在JSON的输出中。 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:3:1","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"Decoding 解析 JSON 数据使用 Unmarshal 方法： func Unmarshal(data []byte, v interface{}) error 我们需要创建一个变量存放解析后的数据 var m Message 调用 Unmarshal err := json.Unmarshal(b, \u0026m) 如果 b 包含有效的 JSON 数据，并且对应 m 的结构，方法返回 err 为 nil， 并且 b 中的数据解析后放入 m。 m = Message{ Name: \"Alice\", Body: \"Hello\", Time: 1294706395881547000, } Unmarshal 如何识别哪个字段存储解析的数据？如果解析获得一个JSON key “Foo”，Unmarshall 会在目标结构体中找合适的字段（以下条件按顺序查找）： 导出的字段，定义了 tag “Foo”（Go Spec ) 导出的字段，名字是 “Foo” 导出的字段，名字是 “FoO” 或 “FOO” 获取其他在大小写不敏感情况下与 “Foo” 匹配 当 Json 数据中的结构和 Go type 不匹配时会发生什么？ b := []byte(`{\"Name\":\"Bob\",\"Food\":\"Pickle\"}`) var m Message err := json.Unmarshal(b, \u0026m) Unmarshal 会解析和目标结构体匹配的字段，忽略不认识的字段。这个特性在当你希望只获取大量json数据中的部分字段时十分有用，这也表示任何任意非导出的字段（小写字母开头的字段）不会被 Unmarshal 影响。 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:3:2","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"使用 Tag 一般在 golang 使用 json package，都会使用标签系统。 // Field appears in JSON as key \"myName\". Field int `json:\"myName\"` // Field appears in JSON as key \"myName\" and // the field is omitted from the object if its value is empty, // as defined above. Field int `json:\"myName,omitempty\"` // Field appears in JSON as key \"Field\" (the default), but // the field is skipped if empty. // Note the leading comma. Field int `json:\",omitempty\"` // Field is ignored by this package. Field int `json:\"-\"` // Field appears in JSON as key \"-\". Field int `json:\"-,\"` // Field appears in JSON as string type. Field int `json:,string,omitempty` Field int `json:,omitempty,string` 通过标签系统可以对转换后的 JSON 数据进行自定义： json:\"myName\" 定义 JSON key 为 myName json:\"myName,omitempty\" 定义 JSON key 为 myName，并且当 empty 的时候删除该字段（empty的定义为：0，false和nil 指针，nil interface和空的slice、map、array和string） json:\"-\" 在 JSON 中忽略该字段 json:\"-,\" 在 JSON 中输出 key 值为 “-” json:,string,omitempty 和 json:,omitempty,string 定义该字段在 JSON 中按 string 类型存储，并且 omitempty。（只有 string、float、integer 和 boolean 字段支持这么定义） ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:3:3","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"高级用法 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:4:0","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"使用 interface{} 解析未知 JSON json pacakge 使用 map[string]interface 和 []interface{} 存储各种 JSON 对象和数组。任意有效的JSON数据类型都能轻松存储到 interface{} 中，默认的具体 Go types 是： bool 对应 JSON boolean float64 对应 JSON numbers（精度上会有损失） string 对应 JSON strings nil 对应 JSON null 一个例子： b := []byte(`{\"Name\":\"Wednesday\",\"Age\":6,\"Parents\":[\"Gomez\",\"Morticia\"]}`) var f interface{} err := json.Unmarshal(b, \u0026f) f = map[string]interface{}{ \"Name\": \"Wednesday\", \"Age\": 6, \"Parents\": []interface{}{ \"Gomez\", \"Morticia\", }, } m := f.(map[string]interface{}) for k, v := range m { switch vv := v.(type) { case string: fmt.Println(k, \"is string\", vv) case float64: fmt.Println(k, \"is float64\", vv) case []interface{}: fmt.Println(k, \"is an array:\") for i, u := range vv { fmt.Println(i, u) } default: fmt.Println(k, \"is of a type I don't know how to handle\") } } ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:4:1","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"Unmarshal 为引用类型申请内存 我们定义一个类型包含引用 type FamilyMember struct { Name string Age int Parents []string } var m FamilyMember err := json.Unmarshal(b, \u0026m) Unmarshalling JSON object 到 FamilyMember 里，相比之前例子， Parents 是引用类型，默认值是nil。如果 JSON object有值写入Parents，Unmarshal 会为 Parents 申请内存。这个是 Unmarshal 对于引用类型（pointers,slicemaps）的典型工作场景。 type Foo struct { Bar *Bar } 如果 JSON object 中包含 Bar 字段，Unmarshal 会为 Bar 申请内存，反之则保持 Bar 为 nil。 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:4:2","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"支持 Streaming json package 支持对 Stream 进行 Decoder 和 Encoder。使用 NewDecoder 和 NewEncoder 装饰 io.Reader 和 io.Writer inteface typs. func NewDecoder(r io.Reader) *Decoder func NewEncoder(w io.Writer) *Encodergo 一个例子： package main import ( \"encoding/json\" \"log\" \"os\" ) func main() { dec := json.NewDecoder(os.Stdin) enc := json.NewEncoder(os.Stdout) for { var v map[string]interface{} if err := dec.Decode(\u0026v); err != nil { log.Println(err) return } for k := range v { if k != \"Name\" { delete(v, k) } } if err := enc.Encode(\u0026v); err != nil { log.Println(err) } } } 对于更普遍的Reader和Writer，Encoder和Decoder类型可以使用在更广泛的场景中。例如对HTTP连接，WebSockets和文件进行读写。 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:4:3","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"需要注意的问题 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:5:0","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"omitempty omitempty 中的 empty 并不仅仅指 empty， 还包括 0，false和nil 指针，nil interface和空的slice、map、array和string。 定义了该 tag 后，boolean、integer、float32、string等属性为默认值时，输出的 JSON 数据就会移除该属性。 在一些需要区分未初始化和0值的场景下，omitempty的使用会造成混淆，这个时候可以使用指针来作为属性。未初始化状态下指针为 nil，输出 JSON 时会被 omit；初始化后 0 值和非 0 值都会正常输出，这样属性的三个状态：未初始化、0值和非0值就可以正常区分了。 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:5:1","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"JSON反序列化成interface{}对Number的处理 JSON 规范中，对于数字类型，并不区分整型还是浮点型。 对于如下 JSON 文本： { \"name\": \"ethancai\", \"fansCount\": 9223372036854775807 } 如果反序列化不指定结构体类型或者变量类型，则JSON中的数字类型，默认被反序列化成 float64 类型 package main import ( \"encoding/json\" \"fmt\" \"reflect\" ) func main() { const jsonStream = ` {\"name\":\"ethancai\", \"fansCount\": 9223372036854775807} ` var user interface{} // 不指定反序列化的类型 err := json.Unmarshal([]byte(jsonStream), \u0026user) if err != nil { fmt.Println(\"error:\", err) } m := user.(map[string]interface{}) fansCount := m[\"fansCount\"] fmt.Printf(\"%+v \\n\", reflect.TypeOf(fansCount).Name()) fmt.Printf(\"%+v \\n\", fansCount.(float64)) } // Output: // float64 // 9.223372036854776e+18 如果 fansCount 精度比较高，反序列化成 float64 类型的数值时存在丢失精度的问题。 如何解决这个问题，看下面的程序： package main import ( \"encoding/json\" \"fmt\" \"reflect\" \"strings\" ) func main() { const jsonStream = ` {\"name\":\"ethancai\", \"fansCount\": 9223372036854775807} ` decoder := json.NewDecoder(strings.NewReader(jsonStream)) decoder.UseNumber() // UseNumber causes the Decoder to unmarshal a number into an interface{} as a Number instead of as a float64. var user interface{} if err := decoder.Decode(\u0026user); err != nil { fmt.Println(\"error:\", err) return } m := user.(map[string]interface{}) fansCount := m[\"fansCount\"] fmt.Printf(\"%+v \\n\", reflect.TypeOf(fansCount).PkgPath() + \".\" + reflect.TypeOf(fansCount).Name()) v, err := fansCount.(json.Number).Int64() if err != nil { fmt.Println(\"error:\", err) return } fmt.Printf(\"%+v \\n\", v) } // Output: // encoding/json.Number // 9223372036854775807 使用 json.NewDecoder 可以将 JSON 数字转换成 json.Number。json.Number 内部实现机制： // A Number represents a JSON number literal. type Number string // String returns the literal text of the number. func (n Number) String() string { return string(n) } // Float64 returns the number as a float64. func (n Number) Float64() (float64, error) { return strconv.ParseFloat(string(n), 64) } // Int64 returns the number as an int64. func (n Number) Int64() (int64, error) { return strconv.ParseInt(string(n), 10, 64) } 其实就是延迟处理，保存了 JSON 数字的原始字符串，使用的时候根据需要进行转换。 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:5:2","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"总结 其实 Golang 对于 json 的支持已经十分完善，通过和标签系统配合，序列化和反序列化 json 字符串只要几行代码，只是在使用过程中要清楚 go 提供的默认机制，避免踩坑。 ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:6:0","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["golang"],"content":"参考 http://docs.studygolang.com/pkg/encoding/json/ https://blog.golang.org/json-and-go http://docs.studygolang.com/pkg/encoding/json/#Marshal https://ethancai.github.io/2016/06/23/bad-parts-about-json-serialization-in-Golang/ ","date":"2018-12-23","objectID":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/:7:0","tags":["golang","json"],"title":"Golang json 序列化","uri":"/2018/golang-json-%E5%BA%8F%E5%88%97%E5%8C%96/"},{"categories":["kubernetes"],"content":"生成代码 除了 default-gen, deepcopy-gen, conversion-gen, 和 openapi-gen 外，还有其他的生成器： go-to-protobuf client-gen lister-gen informer-gen codecgen (使用 ugorji codec快速串行化json) 大部分生成器基于 gengo ，拥有相同的命令行选项。 --verify-only 会检查磁盘上的将要生成的文件。 生成器生成代码时有个 --go-header-file 选项，该选项指定包含生成代码头部内容的文件。头部内容一般是版权信息，放在生成代码的最前面，并且会被稍后的 repo-infra/verify/verify-boilerplane.sh 脚本检查。 执行 make update 会调用一系列脚本 包括以上的生成器。请继续阅读以下段落，因为某些生成器的使用需要一些先决条件，而且执行 make update 耗时太久，下面还会介绍如何单独调用生成器。 ","date":"2018-12-16","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/:1:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（四）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/"},{"categories":["kubernetes"],"content":"Generate protobuf objects 对于任意 core API object ，我们需要生成 Protobuf IDL 和 marshallers。通过调用以下脚本生成： hack/update-generated-protobuf.sh 大部分 object 对于转换成 protobuf 不需要太多的考虑，但是我们需要注意哪些依赖 golang 标准库类型的的 object，可能需要提供一些额外的工作，实践上我们一般使用自定义的 JONST 串行化。pkg/api/serialization_test.go 会测试你的 protobuf 串行化，多运行几次确保没有非兼容的字段。 ","date":"2018-12-16","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/:1:1","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（四）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/"},{"categories":["kubernetes"],"content":"Generate Clientset client-gen 是为顶层 API object 生成 clientsets 的工具。 client-gen 要求每个想要导出的类型前添加 // +genclient 注释，包括 internal type pkg/apis/\u003cgroup\u003e/types.go 和 versioned type staging/src/k8s.io/api/\u003cgroup\u003e/\u003cversion\u003e/types.go 。 如果 apiserver 注册的 API group 名字和文件系统中存储的 group 路径不相同（一般在文件系统中存储会删除 k8s.io 后缀，例如 admission vs admission.k8s.io），你可以在向 client-gen 指定正确的 group name，通过在 doc.go 添加 // +groupName= 注释，当然 internal version pkg/apis/\u003cgroup\u003e/doc.go 和 versioned API staging/src/k8s.io/api/\u003cgroup\u003e/\u003cversion\u003e/types.go 都要添加。 添加 groupName 注释后，执行以下命令生成 client： hack/update-codegen.sh 你可以使用可选选项 // +groupGoName= 使用 Golang 驼峰标识符来为 group 指定别名, 解决冲突。例如 policy.authorization.k8s.io 和 policy.k8s.io。 这两个 group 默认都映射到 Policy() 这个名字的 client 中，这个时候就需要执行 groupGoName 来帮助区分这两个 client group 名。 // +groupName=example2.example.com // +groupGoName=SecondExample 第一个用来定义 RESTfully 接口的资源，第二个用来定义生成的 Golang 代码中的名字，例如在 clientset 中访问该 group verion： clientset.SecondExampleV1() clent-gen 可配置性很强，如果你要为非 kubernets API 生成代码，可以看这篇文档 ","date":"2018-12-16","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/:1:2","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（四）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/"},{"categories":["kubernetes"],"content":"Generate Listers lister-gen 为 client 生成 lister。 这个复用 // +genclient 和 // +groupName= 注释，所有你不用指定额外的注释。 运行 hack/update-codegen.sh 脚本的时候会调用 lister-gen。 ","date":"2018-12-16","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/:1:3","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（四）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/"},{"categories":["kubernetes"],"content":"Generate Informers informer-gen 生成有用的 informers，用于监控 API 资源的变化. 这个复用 // +genclient 和 // +groupName= 注释，所有你不用指定额外的注释。 运行 hack/update-codegen.sh 脚本的时候会调用 informer-gen。 ","date":"2018-12-16","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/:1:4","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（四）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/"},{"categories":["kubernetes"],"content":"Edit json (un)marshaling code 我们只用自动生成的代码来为 API object 进行 marshalling 和 unmarshalling 操作 —— 这比 reflect 提高了系统性能。 自动生成的代码放在每个 versioned API 中： staging/src/k8s.io/api/\u003cgroup\u003e/\u003cversion\u003e/generated.proto staging/src/k8s.io/api/\u003cgroup\u003e/\u003cversion\u003e/generated.pb.go 运行一下脚本重新生成： hack/update-generated-protobuf.sh ","date":"2018-12-16","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/:1:5","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（四）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/"},{"categories":["kubernetes"],"content":"参考 https://github.com/kubernetes/community/blob/master/contributors/devel/api_changes.md#making-a-new-api-version ","date":"2018-12-16","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/:2:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（四）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E5%9B%9B/"},{"categories":["kubernetes"],"content":"修改 Internal structures (unversioned API) 现在是时候开始介绍如何修改内部结构体，这样你修改的 versioned API 才能正常使用。 ","date":"2018-12-14","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%89/:1:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（三）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%89/"},{"categories":["kubernetes"],"content":"Edit types.go 和 versioned APIs 修改类似，内部结构体定义在 pkg/apis/\u003cgroup\u003e/types.go 中。想要修改什么内容就在这里完成，主要内部结构体必须兼容所有的 versioned APIs。 当然，你也必须添加 +k8s:deepcopy-gen tag 来告诉工具需要生成 DeepCopyObject 方法。 ","date":"2018-12-14","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%89/:1:1","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（三）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%89/"},{"categories":["kubernetes"],"content":"Edit validation.go 大部分情况下修改了内部结构体后，需要一些内部输入校验。校验代码放在 pkg/apis/\u003cgroup\u003e/validation/validation.go 。 这个校验对用户体验十分重要，提供良好的错误信息，保证用户的输入正确性。当错误发生的时候，告诉用户为什么以及如何修复。 当然，测试代码也是必须的—— pkg/apis/\u003cgroup\u003e/validation/validation_test.go ","date":"2018-12-14","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%89/:1:2","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（三）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%89/"},{"categories":["kubernetes"],"content":"Edit version conversions 看到这里的时候，你已经完成了 versioned APIs 和 内部结构的修改。如果某些字段名，类型在内部结构和 versioned APIs中存在变化，你必须添加一些从内部结构转换成 versioned APIs的逻辑。如果你在执行 serialization_test 是发现了错误，它可能是在告诉你需要显示指定转换方法。 转换方法的性能会影响 apiserver 的流畅性。因此我们采用自动生成的代码而不是使用通用的转换代码（通用代码使用反射会有很高代价） 转换代码在每个 versionded API 下都有一份，有两个文件： pkg/apis/\u003cgroup\u003e/\u003cversion\u003e/conversion.go 包含手写的转换函数 pkg/apis/\u003cgroup\u003e/\u003cversion\u003e/zz_generated.conversion.go 包含自动生成的转换函数 因为自动生成的转换代码会使用手写的转换代码，因此对手写的转换代码的命名有要求。例如，pkg a 中的类型 X 转换成 pkg b 中的类型 Y， 需要命名成: convert_a_x_To_b_Y 你可以手写转换代码的时候同样可以引用自动生产的转换代码（为了提高效率也应该这样）。 手动添加的转换代码同样要求你添加 test pkg/apis/\u003cgroup\u003e/\u003cversion\u003e/conversion_test.go 当手动添加完必须的转换方法后，你需要重新生成 auto-generated 的代码。执行： make clean \u0026\u0026 make generaged_files make clean 很重要，否则生成的文件会是旧的版本，因为构建系统会使用用户的缓存文件。 make all 也会调用 make generated_files。 make generated_files 也会重新生成 zz_generated.deepcopy.go, zz_generated.defaults.go 和 api/openapi-spec/swagger.json。 如果生成中偶尔出现了编译错误，最简单的解决方法就是删除引起错误的文件重新生成（真暴力） ","date":"2018-12-14","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%89/:1:3","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（三）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%89/"},{"categories":["kubernetes"],"content":"参考 https://github.com/kubernetes/community/blob/master/contributors/devel/api_changes.md#making-a-new-api-version ","date":"2018-12-14","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%89/:2:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（三）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%89/"},{"categories":["kubernetes"],"content":"修改 External API（版本API） 修改版本API是所有修改中最简单的，只需要开发者保持修改后的API相互兼容，比从头写要一个新的 rest API 更容易。 ","date":"2018-12-12","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%8C/:1:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（二）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%8C/"},{"categories":["kubernetes"],"content":"Edit types.go 每个 API 结构体的定义放在 staging/src/k8s.io/api/\u003cgroup\u003e/\u003cversion\u003e/types.go 中。修改这些文件可以实现 API 结构体的修改。 版本 API 内的所有类型和非内嵌字段需要在之前加上描述性注释——用于生成文档。类型注释不要包含类型名。这些注释生成的文档供用户查看，不应该向用户包含类型名。 如果类型需要生成 DeepCopyObject 方法，一般只在顶层类型上添加，例 Pod ，在类型前添加一行注释（example ） // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object Optional 字段必须包含 ,omitempty json tag; ","date":"2018-12-12","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%8C/:1:1","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（二）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%8C/"},{"categories":["kubernetes"],"content":"Edit defaults.go 如果你在 type 中添加了新的字段，那么你可能需要修改默认值，需要在 pkg/apis/\u003cgroup\u003e/\u003cversion\u003e/defaults.go 中添加 case。 注意： 当在给新字段添加默认值的时候，别忘记给所有版本都添加。#66135 老版本的 core ve API 比较特殊， 它的 default.go 过去放在 pkg/api/v1/defaults.go。如果你看到有引用这个路径，那可以确定那个代码过时了。现在 core v1 API 放在了 pkg/apis/core/v1/defaults.go 当你添加完代码，最好再加上一个 test ：pkg/apis/\u003cgroup\u003e/\u003cversion\u003e/defaults_test.go 当你要区分变量是 unset 还是 automatic zero 时，最好使用指针。例如 PodSpec.TerminationGracePeriodSeconds 定义成 *int64。0值表示0秒，nil表示unset。 别忘了 run the tests ","date":"2018-12-12","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%8C/:1:2","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（二）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%8C/"},{"categories":["kubernetes"],"content":"Edit conversion.go 当前还没有修改 internal 结构体，一般没有必要修改 conversion.go。我们会在后面的修改internal api 的章节说明。 当你进行了非兼容的修改后，以下的文件可能需要进行修改： pkg/apis/\u003cgroup\u003e/\u003cversion\u003e/conversion.go pkg/apis/\u003cgroup\u003e/\u003cversion\u003e/conversion_test.go 注意 conversion machinery 并不能通用的处理各种类型的字段和API常量。The client library 自定义了字段引用的转换代码。你还需要为你的 scheme 的 AddFieldLabelConversionFunc 添加调用，帮助它支持字段转换，就像这行代码 ","date":"2018-12-12","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%8C/:1:3","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（二）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%8C/"},{"categories":["kubernetes"],"content":"参考 https://github.com/kubernetes/community/blob/master/contributors/devel/api_changes.md#making-a-new-api-version ","date":"2018-12-12","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%8C/:2:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（二）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%BA%8C/"},{"categories":["kubernetes"],"content":"本系列文章主要介绍开发者如何对 Kuberentes 的 API 进行修改和生成。","date":"2018-12-09","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（一）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/"},{"categories":["kubernetes"],"content":"本文宏观介绍 kubernetes 的 API 各版本之间的联系以及 API 开发的原则。 ","date":"2018-12-09","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/:0:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（一）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/"},{"categories":["kubernetes"],"content":"API Overview ","date":"2018-12-09","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/:1:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（一）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/"},{"categories":["kubernetes"],"content":"API 版本转换 Kubernetes 的 API 分为 Internal 和 External 版本。apiserver 同时支持多个API Version，在为开发提供了很高的自由度的同时也对API版本间的转换提出了更高的鲁棒性要求。 多个 external 版本间的转换， internal 版本处于中心位置，所有版本的 API 都能够转换成 internal 版本，但是其他版本之间能相互转换。所有的 kubernetes 代码 internal 版本结构中进行操作，并在存入etcd 前转换成 external 版本。客户端必须使用 external 版本操作。 以下是一个假设的操作例子： 用户 POST Pod 到 /api/v7beta1/… JSON unmarshall 为 v7beta1.Pod 为 v7beta1.Pod 补充默认值 v7beta1.Pod 转换成 api.Pod 校验 api.Pod 并返回错误 api.Pod 转换成 v6.Pod (稳定版本) v6.Pod marshall 成 JSON 并写入 etcd ","date":"2018-12-09","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/:1:1","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（一）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/"},{"categories":["kubernetes"],"content":"版本兼容 Kubernets 把 API 的版本前向和后向兼容作为最高优先级进行考虑。 想要做到兼容很难，以下几点是实现 API 兼容需要考虑的： 如果添加一个新功能，一定要是非必须的，要让旧版本也能正常工作 不要修改已有接口的定义，包括： 默认值和默认行为，以及其包含的语义 已有 API 类型的字段和值的解释 字段是否是必须字段 可修改字段不要变为非可修改字段 非法字段不要变成合法字段 换个说法： 所有修改前成功调用的 API， 修改后也要能成功调用。 所有不涉及修改的 API 调用，行为和修改前一致。 使用修改后的 API，在和未修改的 apiserver 通信时，不会导致问题。 API 修改支持在不同版本间转换，并不丢失信息。 旧版本的 client 不感知 server 端修改，仍然正常工作。 支持回退到之前不包含修改的 API 版本， 并且不影响没有使用修改部分代码的 client。所有被修改影响到的 API 对象能够隐式回退。 ","date":"2018-12-09","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/:1:2","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（一）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/"},{"categories":["kubernetes"],"content":"参考 https://github.com/kubernetes/community/blob/master/contributors/devel/api_changes.md#making-a-new-api-version ","date":"2018-12-09","objectID":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/:2:0","tags":["kubernetes","API","client-go"],"title":"Kubernetes API 开发（一）","uri":"/2018/kubernetes-api-%E5%BC%80%E5%8F%91%E4%B8%80/"},{"categories":["network"],"content":"上一篇介绍了容器网络广泛采用的两种接入模型：CNM和CNI，通过实现这两种模型定义的接口，我们可以方便的将自定义网络接入或者从容器中移除。本篇我们就要介绍接入容器的网络组网类型。","date":"2018-08-06","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/","tags":["docker","network","container"],"title":"深入浅出容器网络（二）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/"},{"categories":["network"],"content":"容器网络组网类型 将容器介入容器网络前，要先搞清楚接入的容器网络到底使用了什么组网类型。常见的组网类型有underlay l2, overlay l2 和 overlay l3，还有一种是Host网络，也就是容器网络直接接入主机网络也就不存在所谓的容器网络，本文主要介绍前三种容器网络组网类型。 ","date":"2018-08-06","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/:0:0","tags":["docker","network","container"],"title":"深入浅出容器网络（二）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/"},{"categories":["network"],"content":"Underlay 网络 underlay网络一般理解是底层网络，传统的网络组网就是underlay类型，区别于如今流行的隧道技术。 ","date":"2018-08-06","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/:1:0","tags":["docker","network","container"],"title":"深入浅出容器网络（二）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/"},{"categories":["network"],"content":"Underlay L2 underlay l2网络就是2层（链路层）互通的底层网络，传统网络大多数属于这种类型。容器网络使用这种组网，常使用的技术就有IPVLAN L2和MACVLAN。 MACVLAN MACVLAN是linux提供的一种简单的网络子接口技术，它允许你在主机的一个网络接口上配置多个虚拟的网络接口，这些网络interface拥有自己独立的mac地址，也可以配置上独立的ip地址进行通信。macvlan下的容器和主机在同一网段中，共享同一广播域。macvlan和bridge比较类似，但是它省去了bridge的存在，网络效率更高，除此之外，macvlan也完美支持VLAN技术。 如果希望容器放在主机相同的网络中，享受已经存在的网络栈的各种优势，可以考虑macvlan。 https://docs.docker.com/network/macvlan/ http://cizixs.com/2017/02/14/network-virtualization-macvlan IPVLAN IPVLAN和MACVLAN类似，都是从一个主机接口虚拟出多个虚拟网络接口。一个重要区别是所有的虚拟接口都有相同的mac地址，而拥有不同的ip地址。因为所有的虚拟接口要共享mac地址，因此DNCP不能使用mac地址分配ip。 IPVLAN支持两种模式L2和L3，在Underlay L2中，我们使用L2模式。L2模式相比L3模式，父接口工作在类似交换机的模式，子接口可以收到并处理L2报文，相比L3有着更高的处理效率。 https://people.netfilter.org/pablo/netdev0.1/papers/IPVLAN-The-beginning.pdf http://cizixs.com/2017/02/14/network-virtualization-macvlan ","date":"2018-08-06","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/:1:1","tags":["docker","network","container"],"title":"深入浅出容器网络（二）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/"},{"categories":["network"],"content":"Underlay L3 在Underlay L3组网中，可以选择使用IPVLAN的L3模式，该模式下ipvlan 有点像路由器的功能，它在各个虚拟网络和主机网络之间进行不同网络报文的路由转发工作。只要父接口相同，即使虚拟机/容器不在同一个网络，也可以互相 ping 通对方，因为 ipvlan 会在中间做报文的转发工作。 flannel 的 host-gw 组网，calico 的 BGP 组网方式都是 Underlay L3。 flannel网络架构（图片来自openshift） ","date":"2018-08-06","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/:1:2","tags":["docker","network","container"],"title":"深入浅出容器网络（二）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/"},{"categories":["network"],"content":"Overlay 网络 Overlay是在传统网络上虚拟出一个虚拟网络来，传统网络不再需要做任何适配，这样物理网络只对物理层的计算（物理机、虚拟化层管理网），虚拟网络只对应虚拟计算（虚拟机的业务IP）。 ","date":"2018-08-06","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/:2:0","tags":["docker","network","container"],"title":"深入浅出容器网络（二）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/"},{"categories":["network"],"content":"Overlay L2 基于 VXLAN 的 Overlay L2 组网 传统的二层网络范围有限，Overlay l2网络是构建在传统网络上的L2网络，相较于传统l2网络，Overlay l2网络可以跨越多个数据中心，提供了大二层网络。构建在大二层网络上的VM或者容器在动态迁移具有很大的范围和很高的灵活性。 Overlay技术主要用VXLAN、NVGRE、GENEVE等，无论哪种协议都要求在发送方向对报文进行封装外层头，接收方向剥离外层头。VXLAN作为Overlay技术一个代表，是云计算的核心技术之一。 上图的容器Overlay L2网络就由VXLAN实现，通过在UDP包中封装L2报文，实现了容器跨主机进行L2通信。 https://feisky.gitbooks.io/sdn/basic/overlay.html http://techblog.d2-si.eu/2017/05/09/deep-dive-into-docker-overlay-networks-part-2.html ","date":"2018-08-06","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/:2:1","tags":["docker","network","container"],"title":"深入浅出容器网络（二）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/"},{"categories":["network"],"content":"Overlay L3 Overlay L3组网类似Overlay L2，但是节点上会增加一个网关。每个节点上的容器都在同一个子网内，可以直接进行二层通信，但是跨节点的容器间通信只能走L3，都会经过网关转发，性能相比于Overlay L2较弱。但是牺牲的性能获得了更高的灵活性，跨节点的容器可以存在于不同的网段中。 flannel 的最新版本中，VXLAN 模式采用了 Overlay L3 模型。 flannel 基于 VXLAN 的 Overlay L3 组网 ","date":"2018-08-06","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/:2:2","tags":["docker","network","container"],"title":"深入浅出容器网络（二）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/"},{"categories":["network"],"content":"参考 https://www.sdnlab.com/21143.html ","date":"2018-08-06","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/:3:0","tags":["docker","network","container"],"title":"深入浅出容器网络（二）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%BA%8C/"},{"categories":["杂记"],"content":"最近banwagon又被墙了，无奈之下在vultr上申请了机器，使用docker搭建了ssr，记录下造福后人。","date":"2018-05-30","objectID":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/","tags":["docker","ss"],"title":"用docker快速完成翻墙服务搭建","uri":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/"},{"categories":["杂记"],"content":"开始 起因是banwogon的ip又被墙了，由于bandwagon是包年的，换ip并不容易，因此决定使用别家的服务。 Vultr 相比 linode 等老牌厂商，界面简单清爽，提供了月付2.5刀，随时可以删除换ip的VPS，非常适合作为扶墙主机。 ","date":"2018-05-30","objectID":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/:1:0","tags":["docker","ss"],"title":"用docker快速完成翻墙服务搭建","uri":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/"},{"categories":["杂记"],"content":"搭建 使用paypal完成付款，创建完一台 1U/512M 的VPC后，ssh登录机器，开始 ssr 的搭建。这里我推荐使用 CentOS7 镜像，稳定够用。 ","date":"2018-05-30","objectID":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/:2:0","tags":["docker","ss"],"title":"用docker快速完成翻墙服务搭建","uri":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/"},{"categories":["杂记"],"content":"安装 docker yum install docker systemctl start docker ","date":"2018-05-30","objectID":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/:3:0","tags":["docker","ss"],"title":"用docker快速完成翻墙服务搭建","uri":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/"},{"categories":["杂记"],"content":"安装docker-ssr docker run --restart always --privileged -d -p 4567:4567/tcp -p 4567:4567/udp --name ssr-bbr-docker letssudormrf/ssr-bbr-docker -p 4567 -k YOU-PASSWORD -m aes-128-ctr -O auth_aes128_sha1 -o http_post 自从docker出现后，很多事情变得简单。 一条命令就完成了ssr服务端的下载和启动，并且是支持TCP BBR的。启动命令中的具体参数的定义可以查看附录中的ssr-bbr-docker，这里就不多做解释了。命令中的aes-128-ctr、auth_aes128_sha1和http_post作为ssr客户端中的协议类型和混淆协议类型进行配置，端口推荐使用自定义端口，不要用常用的443，容易被封。 想了解大名鼎鼎的BBR的请点这里 ","date":"2018-05-30","objectID":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/:4:0","tags":["docker","ss"],"title":"用docker快速完成翻墙服务搭建","uri":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/"},{"categories":["杂记"],"content":"配置 ssr 客户端 ssr各平台客户端的下载地址，具体配置可以参考客户端帮助文档，这里就不赘述了。 Windows Mac Android IOS OpenWRT ","date":"2018-05-30","objectID":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/:5:0","tags":["docker","ss"],"title":"用docker快速完成翻墙服务搭建","uri":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/"},{"categories":["杂记"],"content":"附录 Vultr ssr-bbr-docker ","date":"2018-05-30","objectID":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/:6:0","tags":["docker","ss"],"title":"用docker快速完成翻墙服务搭建","uri":"/2018/%E7%94%A8docker%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/"},{"categories":["network"],"content":"最近在忙容器网络相关开发，发现里面水很深，准备趁此机会挖个大坑，写一个容器网络系列。","date":"2018-05-27","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/","tags":["docker","network","container"],"title":"深入浅出容器网络（一）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/"},{"categories":["network"],"content":"作为系列第一篇，先开个头，介绍模型和框架，后续再新增实战系列，理论是实战结合才能更好的理解容器网络的设计和实现原理。 ","date":"2018-05-27","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/:0:0","tags":["docker","network","container"],"title":"深入浅出容器网络（一）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/"},{"categories":["network"],"content":"模型 容器技术已经火遍全球，业界迫切需要一个统一的容器网络模型，此时Docker提出了Container Network Model（CNM），Kubernetes提出了Container Network Interface（CNI）。 ","date":"2018-05-27","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/:1:0","tags":["docker","network","container"],"title":"深入浅出容器网络（一）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/"},{"categories":["network"],"content":"CNM Libnetwork是CNM的实现。它为Docker daemon和网络驱动程序之间提供了接口。网络控 制器负责将驱动和一个网络进行对接。每个驱动程序负责管理它所拥有的网络，以及为 该网络提供各种服务，例如IPAM负责ip分配。支持多个驱动程序多个网络同时共存。 网络驱动可以按提供方划分为原生驱动（libnetwork内置的或者Docker支持的）或者远 程驱动（第三方插件）。原生驱动包括none，bridge，overlay一粒macvlan。驱动也可 以按照适用范围划分为本地（单主机）的和全局的（多主机）。 架构 Network Sandbox 包含了一个容器的网络栈。包括了管理容器的网卡，路由表以及DNS设置。一种 Sandbox实现是通过linux的网络命名空间，一个FreeBSD Jail或者其他类似的概念。 一个Sandbox可以包含多个endpoints。 Endpoint 一个endpoint将Sandbox连接到network上。一个endpint的实现可以通过veth pair， Open vSwitch internal port或者其他的方式。一个endpint只能属于一个network， 也只能属于一个sandbox。 Network 一个network是一组可以互相通信的endpoints组成。一个network的实现可以是linux bridge，vlan或者其他方式。一个网络中可以包含多个endpoints。 接口 CNM的接口对比CNI模型较为复杂。提供了remote plugin方式，进行插件化开发。 remote plugin相较与CNI的命令行，更加友好一些，是通过http请求进行的。remote plugin监听一个指定的端口，docker daemon直接通过这个端口和remote plugin进行 操作。 调用过程 Create Network 这一系列调用发生再调用docker network create过程中。 /IpamDriver.RequestPool: 创建subnetpool用于分配IP /IpamDriver.RequestAddress: 为gateway获取IP /NetworkDriver.CreateNetwork: 创建neutron network和subnet Create Container 这一系列调用发生再适用docker run，创建一个container过程中，也可以通过 docker network connect 触发。 /IpamDriver.RequestAddress: 为容器获取IP /NetworkDriver.CreateEndpiont: 创建neutron port /NetworkDriver.Join: 为容器和port绑定 /NetworkDriver.ProgramExternalConnectivity: /NetworkDriver.EndpointOperInfo Delete Network 这一系列调用发生再使用 docker network delete 的过程中。 /NetworkDriver.DeleteNetwork: 删除network /IpamDriver.ReleaseAddress: 释放gateway的IP /IpamDriver.ReleasePool: 删除subnetpool ","date":"2018-05-27","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/:1:1","tags":["docker","network","container"],"title":"深入浅出容器网络（一）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/"},{"categories":["network"],"content":"CNI CNI是由CoreOS提出的一种容器网络规范。已采纳该规范的包括Apache Mesos， Cloud Foundry， Kubernetes，Kurma和rkt。另外Calico 和Weave这些项目也为CNI提供插件。 CNI的规范比较小巧。它规定了一个容器runtime和网络插件之间的简单的契约。这个契 约通过JSON的语法定义了CNI插件所需要提供的输入和输出。 一个容器可以被加入到不同插件所驱动的多个网络之中。一个网络有自己对应的插件和 唯一的名称。CNI插件需要提供两个命令：一个用来将网络接口加入到指定网络，另一 个用来将其移除。这两个接口分别再容器被创建和销毁时调用。 CNI工作流程 docker 已经支持安装CNI插件。https://docs.docker.com/ee/ucp/kubernetes/install-cni-plugin/ 容器runtime(e.g. kubernetes)首先需要分配一个网络命名空间以及一个容器ID。然后连同一些CNI配置 参数传给网络驱动。接着网络驱动会将容器间接入网络，并将分配的IP地址以JSON格 式返回给容器runtime。 目前，CNI的功能涵盖了IPAM, L2 和 L3。端口映射(L4)则由容器runtime自己负责。 CNI也没有规定端口映射的规则。 CNI支持与第三方IPAM的集成，可以用于任何容器runtime。CNM从设计上就仅仅支持 Docker。由于CNI简单的设计，许多人认为编写CNI插件会比编写CNM插件来得简单。 ","date":"2018-05-27","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/:1:2","tags":["docker","network","container"],"title":"深入浅出容器网络（一）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/"},{"categories":["network"],"content":"CNI和CNM的转化 CNI和CNM并非完全不可调和的两个模型。两者概念上有很多相似点，因此可以相互转化， 比如calico项目就支持两种接口模型。 CNI中的container与CNM的sandbox概念一致，CNI中的network与CNM中的network一致。 再CNI中，CNM中的endpoint被隐含在了ADD/DELETE操作中。CNI接口更加简洁，把更多 的工作托管给了容器的管理者和网络的管理者。从这个角度来说，CNI的ADD/DELETE接 口只实现了 docker network connect 和 docker network disconnet 两个命令。 kubernetes/contrib项目提供了一种从CNI向CNM转化的过程。其中原理很简单，就是直 接通过shell脚本执行 docker network connect 和 docker network disconnect 命令，来是心啊从CNI到CNM的转化。 ","date":"2018-05-27","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/:1:3","tags":["docker","network","container"],"title":"深入浅出容器网络（一）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/"},{"categories":["network"],"content":"Reference https://github.com/containernetworking/cni https://thenewstack.io/container-networking-landscape-cni-coreos-cnm-docker/ http://dockone.io/article/1974 http://www.cnblogs.com/xuxinkun/p/5707687.html ","date":"2018-05-27","objectID":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/:2:0","tags":["docker","network","container"],"title":"深入浅出容器网络（一）","uri":"/2018/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E4%B8%80/"},{"categories":["tool"],"content":"CentOS7自带的emacs版本太低，想要更高版本只能编译安装。","date":"2018-01-06","objectID":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/","tags":["emacs","tool"],"title":"在CentOS7中编译安装emacs25","uri":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/"},{"categories":["tool"],"content":"讲在前面 目前使用spacemacs越来越顺手，每个环境我都要装一个，但是在CentOS7环境下默认的emacs版本是23，spacemacs只支持24以上版本，因此需要自行编译安装源代码，本文记录编译安装流程，方便后续查用。 本文记录安装的包可能并不是最精简的，可以自行根据需要进行裁剪。 ","date":"2018-01-06","objectID":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/:1:0","tags":["emacs","tool"],"title":"在CentOS7中编译安装emacs25","uri":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/"},{"categories":["tool"],"content":"下载源码 wget http://mirrors.ustc.edu.cn/gnu/emacs/emacs-25.3.tar.gz tar xzvf emacs-25.3.tar.gz cd emacs-25.3 ","date":"2018-01-06","objectID":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/:2:0","tags":["emacs","tool"],"title":"在CentOS7中编译安装emacs25","uri":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/"},{"categories":["tool"],"content":"安装编译依赖 yum install -y gcc gtk2 gtk2-devel libXpm libXpm-devel libtiff libtiff-devel libjpeg-turbo libjpeg-turbo-devel giflib giflib-devel ncurses-devel texinfo ","date":"2018-01-06","objectID":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/:3:0","tags":["emacs","tool"],"title":"在CentOS7中编译安装emacs25","uri":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/"},{"categories":["tool"],"content":"编译\u0026安装 ./configure --prefix=/usr/local/emacs-25 make make install ","date":"2018-01-06","objectID":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/:4:0","tags":["emacs","tool"],"title":"在CentOS7中编译安装emacs25","uri":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/"},{"categories":["tool"],"content":"下载spacemacs和configure git clone https://github.com/syl20bnr/spacemacs ~/.emacs.d/ git clone https://github.com/firemiles/configures.git ~/configure ln -s ~/Workspace/configures/comm/emacs/spacemacs/spacemacs-private/ ~/.spacemacs.d 至此，spacemacs编译安装完成，尽情享受spacemacs的美妙吧。 ","date":"2018-01-06","objectID":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/:5:0","tags":["emacs","tool"],"title":"在CentOS7中编译安装emacs25","uri":"/2018/%E5%9C%A8centos7%E4%B8%AD%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85emacs25/"},{"categories":["security"],"content":"什么是数字证书 数字证书是一种进行身份识别的电子凭证。 理论上任何人都可以签发数字证书，但是个人签发的数字证书并不被别人信任，不具有安全性。数字证书一般从权威身份认证机构处获得，权威机构使用根证书对申请人的公钥进行数字签名，表明该公钥及相关信息真实可行，由于数字证书一般不可伪造，其他用户可以信任该数字证书。 e字证书可以多级签发，这就形成了证书链，用户通过证书链向签发源头查找，一直找到根证书，如果用户信任根证书，则信任证书链上的所有证书。HTTPS 网站都需要使用数字证书认证，用户通过对网站的数字证书进行认证来确认网站是否可信。 ","date":"2017-07-19","objectID":"/2017/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%88%9D%E6%8E%A2/:1:0","tags":["certificate","security"],"title":"数字证书初探","uri":"/2017/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%88%9D%E6%8E%A2/"},{"categories":["security"],"content":"为什么要数字证书 数字证书时信任的基石。 在开放的互联网上通信，如果不进行加密，就好比在马路上裸奔，谁都可以看到通信内容，毫无隐私可言。 加密通信就需要使用密钥，如何保证安全获得密钥，不被第三方偷看，也不被第三方替换呢。当然你可以直接在线下面对面交换密钥，早先人们也是这么做的，但是现在我们需要在网上完成密钥的交换。我们陷入了鸡生蛋还是蛋生鸡的困境，要安全通信要先交换密钥，要交换密钥需要有安全通信通道，这个时候我们需要一个互相认同的信任基础，由该信任基础帮助完成第一次安全通信通道的建立，这个信任基础就是权威CA机构。 这里以单向认证访问HTTPS网站为例，CA机构为HTTPS网站签发数字证书，用户向网站发出请求时，网站返回数字证书，用户通过对数字证书进行认证，确认网站的可靠性，并取出证书中的公钥，用户自己生成一组密钥，用公钥对用户的密钥加密后返回给网站，网站使用私钥解密出用户密钥，后续的通信就使用密钥完成。整个过程除了发布数字证书外一直处于加密通信的安全信道中，而数字证书的不可伪造信保证了获取数字证书这一步骤的安全性，也就是说整个通信过程时都是安全的。 数字证书的存在解决了第一次通信的信任问题，通信双方可以在此信任的基础上进行下一步动作，打破了鸡生蛋还是蛋生鸡的困境。 ","date":"2017-07-19","objectID":"/2017/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%88%9D%E6%8E%A2/:2:0","tags":["certificate","security"],"title":"数字证书初探","uri":"/2017/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%88%9D%E6%8E%A2/"},{"categories":["security"],"content":"数字证书如何工作 数字证书最大的特点就是不可伪造性，不可移植，和不可否认。它建立在非称加密算法的安全性上。非对称加密算法最有名的应该属RSA了，这里不对算法进行展开说明。 数字证书为什么不可伪造呢，证书拥有者把自己网站的相关信息和公钥放入证书，CA机构对该证书中信息进行散列后使用私钥进行加密，作为数字签名放入证书，用户用CA机构的公钥解密数字签名，对比散列值，确认证书没有被篡改。由于非对称加密的安全性，第三方即使篡改了证书的内容，也无法生成能被CA机构公钥解密并通过散列对比的数字签名，也就保证了通过认证的数字证书通常是可信的。 拿到公钥后就完成了安全通信的第一步，后续用公钥加密这次通信需要使用的密钥给网站，网站后续就使用该密钥加密数据，一次安全通信就这样建立了。 ","date":"2017-07-19","objectID":"/2017/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%88%9D%E6%8E%A2/:3:0","tags":["certificate","security"],"title":"数字证书初探","uri":"/2017/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%88%9D%E6%8E%A2/"},{"categories":["security"],"content":"后记 数字证书还有很多特性，如证书链，证书环，证书权限等，后续再花时间研究补上。 ","date":"2017-07-19","objectID":"/2017/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%88%9D%E6%8E%A2/:4:0","tags":["certificate","security"],"title":"数字证书初探","uri":"/2017/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%88%9D%E6%8E%A2/"},{"categories":["tool"],"content":"为什么是Emacs vi（及其衍生软件）和Emacs的编辑器之战由来以久，vi被称为编辑器之神，而Emacs则是神的编辑器。两款软件有着自己的哲学，vi党认为vi专注编辑，通过扩展能够适应各种编辑需求，是最好的编辑器，继承了Unix小而美的传统；Emacs党认为Emacs不仅仅是编辑器，而是一款操作系统，通过使用Emacs，很多工作都可以在Emacs中完成，这种All-in-one的哲学也有很多人推崇，认为Emacs是一种信仰。 我曾经是坚定的vim党，认为编辑器就应该做编辑器应该做的事，直到遇上Org-mode。Org-mode是Emacs中的一个主模式，相信很多人使用Emacs就是为了使用Org-mode。相比简单的Markdown，Org-mode拥有更加丰富的语法功能，和Emacs的良好配合让写文档变成了一种享受，通过使用Emacs写Org的过程中接触了Emacs的其他功能，被它良好的文档和帮助系统，插件扩展系统深深的吸引，让我明白了，这就是我想要一直使用的工具，vim只是我临时使用会打开的编辑器，而Emacs是可以让我一直在里面工作的编辑器。 配置Emacs的过程中发现了Spacemacs ，这是一个民间的Emacs配置方案，使用layers机制将不同类型的功能进行良好的封装，由社区进行开发维护，开箱即用的特性让Emacs新手也能够很好的使用Emacs。安装了Spacemacs后发现Emacs的使用变得更加简单了，良好的交互式补全功能让Emacs的使用曲线不再那么陡峭。 ","date":"2017-02-03","objectID":"/2017/%E7%A5%9E%E5%99%A8emacs%E4%B8%8A%E6%89%8B/:1:0","tags":["emacs","tool"],"title":"神器Emacs上手","uri":"/2017/%E7%A5%9E%E5%99%A8emacs%E4%B8%8A%E6%89%8B/"},{"categories":["tool"],"content":"Spacemacs的安装 Spacemacs的安装十分简单，先安装Emacs软件，然后下载Spacemacs配置，根据官方仓库的说明操作。 $ git clone https://github.com/syl20bnr/spacemacs ~/.emacs.d 使用Spacemacs的配置前记得备份原先的配置。 为了方便Spacemacs升级，不要修改 ~/.emacs.d 中的文件，新建文件夹~/.spacemacs.d，并将.spacemacs移动到~/.spacemacs.d/init.el，然后进行修改。Spacemacs会加载~/.spacemacs.d目录优先作为用户配置。 ","date":"2017-02-03","objectID":"/2017/%E7%A5%9E%E5%99%A8emacs%E4%B8%8A%E6%89%8B/:2:0","tags":["emacs","tool"],"title":"神器Emacs上手","uri":"/2017/%E7%A5%9E%E5%99%A8emacs%E4%B8%8A%E6%89%8B/"},{"categories":["tool"],"content":"Spacemacs 的简单配置 首先在init.el中添加进几个常用的layers。 dotspacemacs-configuration-layers '( html ;; ---------------------------------------------------------------- ;; Example of useful layers you may want to use right away. ;; Uncomment some layer names and press \u003cSPC f e R\u003e (Vim style) or ;; \u003cM-m f e R\u003e (Emacs style) to install them. ;; ---------------------------------------------------------------- osx chinese ;; pinyin auto-completion better-defaults emacs-lisp git markdown org python ;; (shell :variables ;; shell-default-height 30 ;; shell-default-position 'bottom) ;; spell-checking ;; syntax-checking ;; version-control ) 为了方便管理配置文件，在.spacemacs.d中创建目录custom，作为用户配置目录。在init.el中的user-config函数中添加以下代码： (defun dotspacemacs/user-config () \"Configuration function for user code. This function is called at the very end of Spacemacs initialization after layers configuration. This is the place where most of your configurations should be done. Unless it is explicitly specified that a variable should be set before a package is loaded, you should place your code here.\" ;; import user configurations (add-to-list 'load-path (expand-file-name \"custom\" dotspacemacs-directory)) (require 'init-packages) (require 'init-ui) (require 'init-better-defaults) (require 'init-keybindings) (require 'init-org) (setq custom-file (expand-file-name \"custom/custom.el\" dotspacemacs-directory)) (load-file custom-file) ) 首先使用add-to-list将custom目录添加到load-path变量中，让Emacs可以从用户自定义目录中加载设置，然后是一系列的require命令，该命令会从features变量中寻找相同的名字，如果找到了相应的feature，则使用load函数进行加载，load会使用load-file函数加载相应的文件。如何将自定义的配置添加到features变量中呢，Emacs提供了一个Provide函数通过在配置文件中调用(provide 'init-packages)可以将该配置文件添加到features中，并命名为init-packages。 Emacs默认会将用户自定义自动生成在init.el 文件末尾。将自动生成的代码和手写的代码放在一起不是一个好的选择，因此将自动生成代码分离到custom.el中： (setq custom-file (expand-file-name \"custom/custom.el\" dotspacemacs-directory)) (load-file custom-file) 以上是Spacemacs的简单配置思路。 ","date":"2017-02-03","objectID":"/2017/%E7%A5%9E%E5%99%A8emacs%E4%B8%8A%E6%89%8B/:3:0","tags":["emacs","tool"],"title":"神器Emacs上手","uri":"/2017/%E7%A5%9E%E5%99%A8emacs%E4%B8%8A%E6%89%8B/"},{"categories":["tool"],"content":"Spacemacs 的缺点 如果说Spacemacs有什么缺点的话，就是太容易卡住了，常常需要使用命令： $ pkill -SIGUSR2 -i emacs 该命令可以让Emacs停止耗时的操作，恢复响应。 Spacemacs还提供了精简版本，可以最大限度的提升速度，减少Bug发生，如果发现完整版本使用经常出现Bug，可以考虑使用精简版本。 dotspacemacs-distribution 'spacemacs-base 更多Spacemacs的使用经验后续再继续更新。 ","date":"2017-02-03","objectID":"/2017/%E7%A5%9E%E5%99%A8emacs%E4%B8%8A%E6%89%8B/:4:0","tags":["emacs","tool"],"title":"神器Emacs上手","uri":"/2017/%E7%A5%9E%E5%99%A8emacs%E4%B8%8A%E6%89%8B/"},{"categories":["杂记"],"content":"好久没有更新 hexo，今天手贱把 hexo 和 node 都更新到了最新版本 hexo3 和 node6，然后就悲剧了，hexo 运行各种报错，各种百度后发现是 hexo3 改动比较大，很多功能都作为插件移出了 hexo，需要单独安装。在 hexo2 的基础上进行修改失败，最后决定重新构建一个 hexo3 工程进行迁移。 ","date":"2016-09-13","objectID":"/2016/%E8%BF%81%E7%A7%BB%E5%88%B0hexo3/:0:0","tags":["hexo"],"title":"迁移到hexo3","uri":"/2016/%E8%BF%81%E7%A7%BB%E5%88%B0hexo3/"},{"categories":["杂记"],"content":"安装 为了避免 node@6.x 的兼容问题，使用 nvm 安装并使用 node@5.8 。 $ nvm install 5.8 \u0026\u0026 nvm use 5.8 $ npm install -g hexo-cli $ hexo init blog \u0026\u0026 cd blog \u0026\u0026 npm i \u0026\u0026 hexo s 直接安装初始化默认版本的 hexo 并测试，hexo 默认会安装几个重要插件，包括 hexo-server。如果发现 hexo server 命令不能用，那么就有可能是 _config.yml 文件中的 plugins 配置有问题，尝试删除 plugins 配置再测试，我遇到的问题就是这个原因引起的。 一定要先测试默认配置，我直接用了 hexo2 的配置，然后打开服务器访问就是 404 错误. ","date":"2016-09-13","objectID":"/2016/%E8%BF%81%E7%A7%BB%E5%88%B0hexo3/:1:0","tags":["hexo"],"title":"迁移到hexo3","uri":"/2016/%E8%BF%81%E7%A7%BB%E5%88%B0hexo3/"},{"categories":["杂记"],"content":"迁移 安装并测试通过后，接下来就是迁移旧blog了。 更新 _config.yml，把 next 主题 copy 到 theme 目录下，顺便可以把 next 主题也一起更新了。迁移 source 下的文件夹到新的 source 目录下。 $ hexo g $ hexo s 测试下迁移后的内容，没有问题迁移就成功了。 ","date":"2016-09-13","objectID":"/2016/%E8%BF%81%E7%A7%BB%E5%88%B0hexo3/:2:0","tags":["hexo"],"title":"迁移到hexo3","uri":"/2016/%E8%BF%81%E7%A7%BB%E5%88%B0hexo3/"},{"categories":["杂记"],"content":"添加域名 阿里云搞活动买了个域名 firemiles.top ， 为了不浪费，给博客分配了个子域名 blog.firemiles.top。 在 source 下添加 CNAME 文件，内容就是 blog.firemiles.top。 ","date":"2016-09-13","objectID":"/2016/%E8%BF%81%E7%A7%BB%E5%88%B0hexo3/:3:0","tags":["hexo"],"title":"迁移到hexo3","uri":"/2016/%E8%BF%81%E7%A7%BB%E5%88%B0hexo3/"},{"categories":["杂记"],"content":"参考链接 hexo hexo-issues Hexo搭建Github-Pages博客填坑教程 Hexo+Github域名和github绑定的问题 ","date":"2016-09-13","objectID":"/2016/%E8%BF%81%E7%A7%BB%E5%88%B0hexo3/:4:0","tags":["hexo"],"title":"迁移到hexo3","uri":"/2016/%E8%BF%81%E7%A7%BB%E5%88%B0hexo3/"},{"categories":["crawler"],"content":"一直想写一个种子搜索引擎，搜集资料开始写后遇到了一个难关：爬虫的效率太低，运行一天也爬不到一条 消息，而且阿里云在我的程序开始运行后一天就无法远程登录，只能重启服务器。一度计划被搁置了下来，直到最近事情出现了转机，我找到了更好的爬虫原型，并且对比之下发现了旧爬虫效率低下的原因，特写下此文记录。 ","date":"2016-02-14","objectID":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/:0:0","tags":["DHT","BitTorrent","crawler"],"title":"DHT 爬虫初步","uri":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/"},{"categories":["crawler"],"content":"DHT DHT（Distributed Hash Table，分布式哈希表）。DHT 系统中有三个值，分别是节点标识（节点 ID），对象关键字（key）和对象值（value），节点存储的是对象的 \u003ckey,value\u003e 对。 大部分结构式 P2P 网络都使用 DHT 系统。DHT 的主要功能包括3个内容： 标识符的生成和管理 提供重叠网络中的查询定位的路由服务 对提供的服务或文件的信息进行管理 DHT 系统有四个基本操作（以 Kademlia 算法为主）： ping 操作。作用是探测一个节点，用以判断该节点是否仍然在线。 store 操作，作用是通知一个节点存储一个\u003ckey,value\u003e对，以便以后查询需要。 find_node 操作，作用是从自己的“路由表”对应的 K 桶中返回 k 个节点信息(IP address, UDP port, Node ID)给发送者。 find_value 操作，作用是把 info-hash（key） 作为参数，如果本操作接收者正好存储了 info-hash 的 peers（value） 则返回 peers list，否则从自己的“路由表“中返回离 info-hash 更近的 k 个节点信息（同 find_node 过程）。 ","date":"2016-02-14","objectID":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/:1:0","tags":["DHT","BitTorrent","crawler"],"title":"DHT 爬虫初步","uri":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/"},{"categories":["crawler"],"content":"Kademlia DHT 系统有很多资源定位算法，包括 Chord，Pastry，CAN 和 Kademlia 等。其中 bittorrent 中的 DHT 系统选用了 Kademlia 算法作为资源定位算法。 Kademlia 与其他 DHT 算法相同，所有信息均以 \u003ckey, value\u003e 对的散列表条目形式加以存储，这些 \u003ckey, value\u003e 对分散地存储在各节点上。每个 ID 和关键字值有160bit。为了发布和寻找 \u003ckey, value\u003e 对，Kademlia 采用两节点之间距离（Distance）的概念。与其他 DHT 算法相比，两节点距离不依靠物理距离、跳数，而是通过异或算法（XOR）为距离度量基础，建立了一个全新的 DHT 拓扑结果，大大提高了查询速度。 节点 X 要查找 ID 值为 t 的节点 T，过程如下： 计算 X 到 T 的距离 $d(x, t) = x \\oplus t$ 从 X 的第 [$log_2 d$]个 K 桶中取出 α 个节点的信息（各个实现 α 值不一样，有些是3有些则等于k值），同时进行 FIND_NODE 操作。如果这个K 桶中的信息少于 α 个，则从附近多个桶中选择距离最接近d 的总共α个节点。 对接受到查询操作的每个节点，如果发现自己就是 T，则回答自己是最接近 T 的。否则测量自己和 T 的距离，并从自己对应的 K 桶中选择 α 个节点的信息给 X。 X 对新接受到的每个节点都再次执行 FIND_NODE 操作，此过程不断重复执行，直到每一个分支都有节点响应自己是最接近 T 的，或者说 FIND_NODE 操作返回的节点值没有都已经被查找过了，即找不到更近的节点了。 通过上述查找操作，X 得到了 k 个最接近 T 的节点信息。 注意：这里用『最接近』这个说法，是因为 ID 值为t 的节点不一定存在网络中，也就是说 t 没有分配给任何一台电脑。 bt-dht 中查找 peers-list 的过程则换成 find_value 动作，但注意前文提到的区别即可以有类似的描述。 注意：Kademlia 算法运行一段时间后，大部分 \u003ckey,value\u003e 对象会在节点 X 聚集，其中 X 的 ID 值和 key 的距离很近，也就是 Kademlia 算法查找资源的依据。 ","date":"2016-02-14","objectID":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/:2:0","tags":["DHT","BitTorrent","crawler"],"title":"DHT 爬虫初步","uri":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/"},{"categories":["crawler"],"content":"DHT 爬虫协议 这里指的 DHT 爬虫主要是指使用 Kademlia 算法的 bt-dht 爬虫。bt-dht 使用 krpc 协议和 bencode 编码。 bt-dht 请求有四种，分别是： ping（回复 pong) find_node（回复 found_node） get_peers（回复 got_peers） announce_peer 基本和 DHT 的四种基本操作一致，这里要介绍的是 announce_peer 请求，该请求表示节点 X 当前正在下载请求中指定的资源，发送的目标节点是之前向 X 发送过 got_peers 的节点，并且携带有 got_peers 中带有的 token 作为验证。bt-dht 爬虫主要搜集的就是 announce_peer 中携带的资源 info_hash 和 get_peers 中的资源 info_hash，可以以此了解资源的热度。 ","date":"2016-02-14","objectID":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/:3:0","tags":["DHT","BitTorrent","crawler"],"title":"DHT 爬虫初步","uri":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/"},{"categories":["crawler"],"content":"DHT 爬虫实现 在 Github 上已经有很多 DHT 爬虫的实现，简单列举几个我测试过的： Fuck-You-GFW/simDHT wuzhenda/simDHT 0x0d/dhtfck 其中两个 simDHT 都是真正的爬虫，而 dhtfck 更接近一个正常的 DHT 节点。不幸的是我一开始采用了 dhtfck 作为参考开发，即使开启了 32 个爬虫进行爬取，收到的 announce 数也寥寥无几。一度爬虫的开发陷入停滞，因为找不到提高爬虫效率的方法，看到网上博客介绍的爬虫效率，我只能无奈，直到发现了 simDHT，这个纯正的 DHT 爬虫。 对比了两个爬虫间的区别，我发现了问题的根源，dhtfck 每次只向数量很少的节点发出 find_node 请求，并一直维护 node 池中的节点，导致最终爬虫只被少数节点记录，收集效率当然不高。而 simDHT 则是以一定频率按顺序向节点列表中的节点发出 find_node 请求，并删除旧的节点，这样发现该爬虫的节点以很快的速度增长，而且不需要定期维护节点池。 获取了 info_hash 后可以从一些种子网站下取对应的种子，如 torcache ；也可以构造磁力链接然后用迅雷等工具下载；也可以借助 libtorrent 库下载内容，甚至借助 bittorrent 协议中的 Extension for Peers to Send Metadata Files ，通过发出 announce_peer 的节点获取资源。 ","date":"2016-02-14","objectID":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/:4:0","tags":["DHT","BitTorrent","crawler"],"title":"DHT 爬虫初步","uri":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/"},{"categories":["crawler"],"content":"参考资料 写了个磁力搜索的网页 搜片神器 BitTorrent DHT 协议中文翻译 DHT Protocol Extension for Peers to Send Metadata Files Extension Protocol ","date":"2016-02-14","objectID":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/:5:0","tags":["DHT","BitTorrent","crawler"],"title":"DHT 爬虫初步","uri":"/2016/dht-%E7%88%AC%E8%99%AB%E5%88%9D%E6%AD%A5/"},{"categories":["LDD"],"content":"主要开发流程介绍 module_init宏和module_exit宏 当模块装载时需要调用module_init宏指定的函数， 卸载时需要调用 module_exit宏指定的函数 以下是简单的init流程： 初始化设备 初始化file_operation 获取字符设备号 注册字符设备 当卸载模块时，需要释放申请的设备号。 主设备号和次设备号 对字符设备的访问是通过文件系统内的设备名称进行的。那些名称被称为特殊 文件、设备文件，或者简单称为文件系统树的节点，他们通常位于/dev目录。 通常而言，主设备号表示设备对应的驱动程序。例如，/dev/null和/dev/zero 由驱动程序1管理，而虚拟控制台和串口终端由驱动程序4管理。 现代的Linux内核允许多个驱动程序共享主设备号，但我们看到的仍然按照”一个主设备号对应一个驱动程序“的原则组织。次设备号的作用被加强了，一个主设备号加一个次设备号可以对应一个驱动程序。 /proc/devices 可以查看注册的主设备号；/proc/modules 可以查看正在使用模块的进程数两个文件中的module名字不同，devices中的是用户设置的name，modules中的是名字module.ko中的module。 设备编号的内部表达 在内核中dev_t类型（在linux/types.h中定义）用来保存设备编号——包括主设备号和次设备号。我们的代码不应该对设备编号的组织做任何假定，而应该始终使用linux/kdev_t.h中定义的宏。 MAJOR(dev_t dev); MINOR(dev_t dev); 相反，如果要将主设备号和次设备号转换成dev_t类型，则使用： MKDEV(int major, int minor); 分配和释放设备编号 在建立一个字符设备之前，我们的驱动程序首先要做的事情就是获得一个或者多个设备编号。完成该工作的必要函数是 register_chrdev_region，该函数在linux/fd.h中声明： int register_chrdev_region(dev_t first, unsigned int count, char *name); 其中 first 是要分配的设备编号范围的起始值。first的次设备号经常被置为0，但对该函数不是必须的。count 是所请求的连续设备编号的个数。 name 是和该编号范围关联的设备名称，它将出现在/proc/devices和sysfs中。 如果我们知道可用的设备编号，则 register_chrdev_region 会工作很好。但是 我们进程不知道将要用哪些主设备号；应此提供了以下函数 int alloc_chrdev_region(dev_t *dev, unsigned int firstminor, unsigned int count, char *name); dev 用于输出参数，成功调用后保存已分配范围的第一个编号。 firstminor 应该是 要使用的被请求的第一个次设备号，通常是0。 count 和 name 参数和 register_chrdev_region 相同。 无论使用哪种方法分配设备号，都应该在不再使用它们时释放这些设备编号。 void unregister_chrdev_region(dev_t first, unsigned int count); 通常我们在清除模块中调用 unregister_chrdev_region 函数。 一些重要的数据结构 ","date":"2015-01-04","objectID":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/:0:0","tags":["linux","driver"],"title":"LDD阅读笔记之字符设备驱动","uri":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/"},{"categories":["LDD"],"content":"文件操作 迄今为止，我们已经为自己保留了一些设备编号，但尚未将任何驱动程序的操作连接到这些 编号。file_operations结构就是用来建立这种连接的。 struct file_operations { struct module *owner; loff_t(*llseek) (struct file *, loff_t, int); ssize_t(*read) (struct file *, char __user *, size_t, loff_t *); ssize_t(*aio_read) (struct kiocb *, char __user *, size_t, loff_t); ssize_t(*write) (struct file *, const char __user *, size_t, loff_t *); ssize_t(*aio_write) (struct kiocb *, const char __user *, size_t, loff_t); int (*readdir) (struct file *, void *, filldir_t); unsigned int (*poll) (struct file *, struct poll_table_struct *); int (*ioctl) (struct inode *, struct file *, unsigned int, unsigned long); int (*mmap) (struct file *, struct vm_area_struct *); int (*open) (struct inode *, struct file *); int (*flush) (struct file *); int (*release) (struct inode *, struct file *); int (*fsync) (struct file *, struct dentry *, int datasync); int (*aio_fsync) (struct kiocb *, int datasync); int (*fasync) (int, struct file *, int); int (*lock) (struct file *, int, struct file_lock *); ssize_t(*readv) (struct file *, const struct iovec *, unsigned long, loff_t *); ssize_t(*writev) (struct file *, const struct iovec *, unsigned long, loff_t *); ssize_t(*sendfile) (struct file *, loff_t *, size_t, read_actor_t, void __user *); ssize_t(*sendpage) (struct file *, struct page *, int, size_t, loff_t *, int); unsigned long (*get_unmapped_area) (struct file *, unsigned long, unsigned long, unsigned long, unsigned long); }; struct file_operations scull_fops = { .owner = THIS_MODULE, .llseek = scull_llseek, }; //C99 syntax ","date":"2015-01-04","objectID":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/:1:0","tags":["linux","driver"],"title":"LDD阅读笔记之字符设备驱动","uri":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/"},{"categories":["LDD"],"content":"file结构 在linux/fs.h中定义的struct file是设备驱动程序所使用的第二个最重要的数据结构。 注意：file结构和用户空间程序中的FILE没有任何关联。FILE是C库中的定义的结构， 而struct file是一个内核结构，不会出现在用户程序中（文件描述符应该是指向该结构体）。 struct file { mode_t f_mode; //文件模式 loff_t f_pos; //当前读写位置 unsigned int f_flags; //文件标志，如O_RDONLY、O_NONBLOCK和O_SYNC。 struct file_operations *f_op; //与文件相关的操作。 void *private_data; //open系统调用在调用驱动程序的open方法前将这个 //指针置为NULL。 struct dentry *f_dentry;//文件对应的目录项(dentry)结构。 //filp-\u003ef_dentry-\u003ed_inode …… } ","date":"2015-01-04","objectID":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/:2:0","tags":["linux","driver"],"title":"LDD阅读笔记之字符设备驱动","uri":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/"},{"categories":["LDD"],"content":"inode结构 内核用inode结构在内部表示文件，因此它和file结构不同，后者表示打开的文件描述符。对 单个文件，可能会有多个表示打开的文件描述符的file结构，但它们都指向单个inode结构。 struct inode { dev_t i_rdev; //对表示设备文件的inode结构， //该字段包含了真正的设备编号 struct cdev *i_cdev;//表示字符设备的内核内部结构。 …… i_rdev 的类型在2.5开发系列版本中发生了变化，为了鼓励编写可移植性更强的代码， 内核开发者增加了两个新的宏。 unsigned int iminor(struct inode *inode); //获取次设备号 unsigned int imajor(struct inode *inode); //获取主设备号 字符设备的注册 内核内部使用struct cdev结构来表示字符设备。在内核调用设备的操作之前，必须分配 并注册一个或者多个上述结构。为此，我们的代码需要包含linux/cdev.h，其中定义 了这个结构以及与其相关的一些辅助函数。 struct cdev { struct kobject kobj; struct module *owner; const struct file_operations *ops; struct list_head list; dev_t dev; unsigned int count; }; 有一个老的机制可以避免使用cdev结构，但是新代码应该使用新技术。 struct cdev *my_cdev = cdev_alloc(); my_cdev-\u003eops = \u0026my_fops; 我们可以将cdev结构嵌入到自己的设备特定结构中（有点类似派生的C版本）。 如果没有通过 cdev_alloc 申请，则我们需要用下面的代码来初始化已分配的结构： void cdev_init(struct cdev *cdev, struct file_operations *fops); 还有一个字段需要初始化，和file_operations一样，struct cdev也有一个所有者字段， 应设置为THIS_MODULE。 在设置完cdev结构后，最后的步骤是告诉内核该结构的信息： int cdev_add(struct cdev *dev, dev_t num, unsigned int count); num 是该设备对应的第一个设备编号，count是应该和该设备关联的设备编号数量。 只要 cdev_add 成功返回，我们的设备就要开始工作了，它的操作会被内核调用。 要从系统移除一个字符设备，做如下调用： void cdev_del(struct cdev *dev); 在将cdev通过 cdev_del 移除后，就不应该再访问cdev结构了。 ","date":"2015-01-04","objectID":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/:3:0","tags":["linux","driver"],"title":"LDD阅读笔记之字符设备驱动","uri":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/"},{"categories":["LDD"],"content":"Scull中的设备注册 static void scull_setup_cdev(struct scull_dev *dev, int index) { int err, devno = MKDEV(scull_major, scull_minor+index); cdev_init(\u0026dev-\u003ecdev, \u0026scull_fops); dev-\u003ecdev.owner = THIS_MODULE; dev-\u003ecdev.ops = \u0026scull_fops; // this expression is redundancy ? err = cdev_add(\u0026dev-\u003ecdev, devno, 1); if(err){ printk(KERN_NOTICE \"Error %d adding scull%d\", err, index); } } 因为cdev结构被内嵌到了strcut scull_dev中，因此必须调用cdev_init来执行该结构的初始化。 ","date":"2015-01-04","objectID":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/:4:0","tags":["linux","driver"],"title":"LDD阅读笔记之字符设备驱动","uri":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/"},{"categories":["LDD"],"content":"早期办法 int register_chrdev(unsigned int major, const char *name, struct file_operations *fops); 对 register_chrdev 的调用将为 给定的主设备号注册0～255作为次设备号，并为 每个设备建立一个对应的默认cdev结构。使用这一接口的驱动程序必须能够处理所有 256个次设备号上的 open 调用。对应的移除函数： int unregister_chrdev(unsigned int major, const char *name); open和release ","date":"2015-01-04","objectID":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/:5:0","tags":["linux","driver"],"title":"LDD阅读笔记之字符设备驱动","uri":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/"},{"categories":["LDD"],"content":"open方法 open 方法提供给驱动程序以初始化的能力（和module_init的不同），open应完成如下 工作： 检查设备特定的错误（如设备未就绪或类似硬件问题） 如果设备首次打开，对其进行初始化。 如有必要，更新f_op指针。 分配并填写置于filp-\u003eprivate_data里的数据结构。 open 方法的原型如下： int (*open) (struct inode *inode, struct file *filp); inode参数在i_cdev字段中包含了我们需要的信息，即我们先前设定的cdev结构。我们通常需要 包含它的scull_dev结构，内核黑客为我们提供了此类技巧，它通过定义在linux/kernel.h 中的container_of宏实现： container_of(pointer, container_type, container_field); struct scull_dev *dev; dev = container_of(inode-\u003ei_cdev, struct scull_dev, cdev); //cdev是成员名 flip-\u003eprivate_data = dev; 另一个确定要打开的设备的方法是：检查保存在inode中的次设备号。如果使用了 register_chrdev 注册设备，则必须使用该技术。 经过简化的 scull_open 代码： int scull_open(struct inode *inode, struct file *filp) { struct scutll_dev *dev; dev = container_of(inode-\u003ei_cdev, struct scull_dev, cdev); filp-\u003eprivate_data = dev; if((filp-\u003ef_flags\u0026O_ACCMODE)==O_WRONLY){ scull_trim(dev); } return 0; } 由于我们没有维护scull的打开计数，只维护模块的使用计数，因此也就没有类似\"首次打开时初始化设备\"这类动作。 ","date":"2015-01-04","objectID":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/:6:0","tags":["linux","driver"],"title":"LDD阅读笔记之字符设备驱动","uri":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/"},{"categories":["LDD"],"content":"release方法 release 方法和 open 相反，有时这个方法被称为 device_close。 释放由 open 分配的、保存在filp-\u003eprivate_data中的所有内容。 在最后一次关闭操作时关闭设备。 注： 后面scull_open为每种设备都替换了不同的filp-\u003ef_op，所以不同的设备由 不同的函数关闭 当关闭一个设备文件的次数比打开它的次数多时，系统中会发生什么？ 答案很简单：并不是每个close系统调用都会引起对release方法的调用。只有 真正释放设备数据结构的 close 调用才会调用这个方法。内核对每个file 结构维护其被使用多少次的计数器。无论 fork 还是 dup 都不会创建新 的数据结构（仅由open创建），他们只是增加已有结构中的计数。只有file结 构的计数归零是，close系统调用才会执行release方法，这只在删除这个结 构时才会发生。保证了一次open只会看到一次release调用。 注意：flush方法在应用程序每次调用close时都会调用。 read和write read 和 write 方法完成的任务是相似的，亦即，拷贝数据到应用程序空间， 或者反过来。 ssize_t read(struct file *filp, char __user *buff, size_t count, loff_t *offp); ssize_t write(struct file *filp, const char __user *buff, size_t count, loff_t *offp); 需要说明的是read和write方法的buff参数是用户空间的指针。因此，代码不能直接 引用其中内容。原因如下： 随着驱动程序所运行的架构不同或者内核配置不同，在内核模式运行时，用户 空间的指针可能是无效的。 即使该指针在内核空间中代表相同的东西，但用户空间的内存是分页的，而在系统 调用被调用时，涉及到的内存可能根本不在RAM中。对用户空间的内存的直接引用 将导致页错误，而这对内核代码来说是不允许发生的事情。其结果可能是“oops”。 我们讨论的指针可能由用户程序提供，而该程序可能存在缺陷或者是个恶意程序。 为确保安全，需要使用下面几个函数（由linux/uaccess.h中定义） unsigned long copy_to_user(void __user *to, const void *from, unsigned long count); unsigned long copy_from_user(void *to, const void __user *from, unsigned long count); 当内核空间运行的代码访问用户空间的时候必须多加小心，因为被寻址的用户页面 可能不存在当前内存中，于是虚拟内存子系统经该进程转入休眠，知道该页面被加载 到期望位置。对驱动开发人员来说，这带来的结果就是任何访问用户空间的函数都是 必须可重入的（异步信号安全），必须能和其他驱动程序函数并发执行，更特别的是 必须处于能够合法休眠的状态。 readv和writev Unix系统很早就已支持两个可选的系统调用：readv和writev。 如果驱动程序没有提供用于处理向量操作的方法，readv和writev会通过对read和 write方法的多次调用来实现。但在很多情况下，直接在驱动程序中实现readv和writev 可以获得更高的效率。 ssize_t (*readv) (struct file *filp, const struct iovec *iov, unsigned long count, loff_t *ppos); ssize_t (*writev) (struct file *filp, const struct iovec *iov, unsigned long count, loff_t *ppos); iovec结构定义在linux/uio.h中： struct iovec { void __user *iov_base; __kernel_size_t iov_len; } 每个iovec结构都描述了一个用于传输的数据块。函数中的count参数指明要操作多少 个iovec结构。 正确而有效率的操作经常需要驱动程序做一些更为巧妙的事情。 例如，磁带驱动程序的writev就应将所有iovec结构的内容作为磁带上的单个记录写入。 如果忽略他们，内核会通过read和write模拟它们。 实例 /* * ===================================================================================== * * Filename: scull.c * * Description: this is a first driver from ldd3 * ignore mutithread race, data overflow, * just a simple example. * * Version: 1.0 * Created: 11/29/2014 09:00:04 PM * Revision: none * Compiler: gcc * * Author: Xu Jianjun(firemiles), * Organization: * * ===================================================================================== */ #include \u003clinux/module.h\u003e #include \u003clinux/init.h\u003e #include \u003clinux/fs.h\u003e #include \u003clinux/cdev.h\u003e #include \u003clinux/uaccess.h\u003e #include \u003clinux/slab.h\u003e MODULE_LICENSE(\"GPL\"); static long scull_ioctl (struct file *file, unsigned int cmd, unsigned long n); static ssize_t scull_write (struct file *file, const char __user *buff, size_t count, loff_t *f_ops ); static ssize_t scull_read (struct file *file, char __user *buff, size_t count, loff_t *f_ops ); static loff_t scull_llseek (struct file *file, loff_t f_ops, int count); static int scull_release (struct inode *inode, struct file *file ); static int scull_open (struct inode *inode, struct file *file ); static int scull_major = 0; static int scull_minor = 0; struct scull_dev { char *data; size_t maxlen; //buffer length size_t len; //data length struct cdev cdev; }scull_dev1; struct file_operations scull_fops = { .owner = THIS_MODULE, .llseek = scull_llseek, .read = scull_read, .write = scull_write, .unlocked_ioctl = scull_ioctl, //new api .open = scull_open, .release= scull_release, }; /* * === FUNCTION ====================================================================== * Name: scull open * Description: * ===================================================================================== */ static int scull_open (struct inode *inode, struct file *filp ) { struct scull_dev *dev; dev = container_of(inode-\u003ei_cdev, struct scull_dev, cdev); filp-\u003eprivate_data = dev; if(dev-\u003edata == NULL){ dev-\u003edata = (char *)kmalloc(1024, GFP_KERNEL); dev-\u003emaxlen = 1024; dev-\u003elen = 0; } return 0; } /* ----- end of function scull open ----- */ /* * === FUNCTION =================","date":"2015-01-04","objectID":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/:7:0","tags":["linux","driver"],"title":"LDD阅读笔记之字符设备驱动","uri":"/2015/ldd%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/"}]